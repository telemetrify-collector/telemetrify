# Copyright (C) Deutsche Telekom AG
#
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

import logging

from telemetrify.common.mod import *
from telemetrify.common.utils import *
from telemetrify.nsoapi.cdb import *
from telemetrify.nsoapi.conf import *
from telemetrify.nsoapi.conv import *
from telemetrify.nsoapi.proto import *
from telemetrify.nsoapi.schema import *

SUB_TYPE_RUNNING = CDB_SUB_TYPE_RUNNING
# SUB_TYPE_RUNNING_TWOPHASE = CDB_SUB_TYPE_RUNNING_TWOPHASE
SUB_TYPE_OPERATIONAL = CDB_SUB_TYPE_OPERATIONAL

def sub_type_str(sub_type: int) -> str:
    if sub_type == SUB_TYPE_RUNNING:
        return "SUB_TYPE_OPERATIONAL"
    elif sub_type == SUB_TYPE_OPERATIONAL:
        return "SUB_TYPE_OPERATIONAL"
    else:
        raise Exception("Not Implemented")

class SubscriptionSpec(object):
    @property
    identity: SubscriptionIdentity
    @property
    is_required: bool

    def __init__(self, identity: SubscriptionIdentity, is_required: bool):
        self.identity = identity
        self.is_required = is_required

    def __str__(self) -> str:
        return "SubscriptionSpec(" + str(self.identity) + ", is_required=" + str(self.is_required) + ")"

    def __repr__(self):
        return self.__str__()

class SubscriptionIdentity(object):
    @property
    path: Keypath
    @property
    sub_type: int

    def __init__(self, path: Keypath, sub_type: int):
        self.path = path
        self.sub_type = sub_type

    def __str__(self) -> str:
        return "SubscriptionIdentity(" + str(self.path) + ", " + sub_type_str(self.sub_type) + ")"

    def __repr__(self):
        return self.__str__()

extension SubscriptionIdentity(Hashable):
    def __eq__(self, other: SubscriptionIdentity) -> bool:
        return self.path == other.path and self.sub_type == other.sub_type

    def __hash__(self) -> int:
        return safe_hash(hash(self.path) + hash(self.sub_type))

class Refiner(object):
    @property
    priority: int
    @property
    subscription_dependencies: list[SubscriptionSpec]
    @property
    refiner_dependencies: list[int]

    def __init__(self, subscription_dependencies: list[SubscriptionSpec], refiner_dependencies: list[int]):
        self.priority = 0
        self.subscription_dependencies = subscription_dependencies
        self.refiner_dependencies = refiner_dependencies

    @staticmethod
    def id() -> int:
        raise Exception("Not Implemented")

    mut def update(self, tree: TNode, input_subs: dict[SubscriptionIdentity, list[Keypath]], input_refiners: dict[int, (Refiner, list[Keypath])]) -> list[Keypath]:
        raise Exception("Not Implemented")

    def state(self, keys: Keypath) -> ?value:
        raise Exception("Not Implemented")

# extension Refiner(Ord):
#     def __eq__(self, other) -> bool:
#         self.priority == other.priority and self.id() == other.id()

#     def __lt__(self, other) -> bool:
#         return self.priority < other.priority #or self == other and self.id < other.id

# Workaround for https://github.com/actonlang/acton/issues/1126
extension Refiner(Ord2):
    def eq(self, other) -> bool:
        return self.priority == other.priority and self.id() == other.id()

    def lt(self, other) -> bool:
        return self.priority < other.priority #or self == other and self.id < other.id

extension Refiner(Hashable):
    def __eq__(self, other) -> bool:
        return self.priority == other.priority and self.id() == other.id()

    def __hash__(self) -> int:
        return safe_hash(self.id() + 1000002043 * self.priority)

def _get_subtree_path_keys(node: TNode, path: Keypath) -> list[Keypath]:
    keys: list[Keypath] = []
    curr_keys: list[Id] = []
    stack: list[(TNode, int, int)] = []

    stack.append((node, 0, 0))

    path_len = len(path)

    while stack:
        n, path_index, curr_keys_len = list_pop(stack)

        while len(curr_keys) > curr_keys_len:
            list_pop(curr_keys)

        if path_index < path_len:
            key = n.key()
            if key is not None:
                curr_keys.append(key)
                curr_keys_len += 1

            _id = path[path_index]
            if isinstance(_id, Key):
                if _id.is_wildcard():
                    children = list(n.iter())
                    if children:
                        for c in list_reversed(children):
                            stack.append((c, path_index + 1, curr_keys_len))
                else:
                    c = n[_id]
                    if c:
                        stack.append((c, path_index + 1, curr_keys_len))
            elif isinstance(_id, Tag):
                c = n[_id]
                if c.exists():
                    stack.append((c, path_index + 1, curr_keys_len))
        else:
            keys.append(Keypath(list(curr_keys)))

    return keys

class PassthroughRefiner(Refiner):
    @property
    subtrees: dict[Keypath, TNode]

    def __init__(self, subscription_spec: SubscriptionSpec):
        Refiner.__init__(self, [subscription_spec], [])
        self.subtrees = {}

    mut def update(self, root: TNode, input_subs: dict[SubscriptionIdentity, list[Keypath]], input_refiners: dict[int, (Refiner, list[Keypath])]) -> list[Keypath]:
        _subtrees: dict[Keypath, TNode] = {}

        sub_identity = self.subscription_dependencies[0].identity
        keypaths = input_subs[sub_identity]

        for keypath in keypaths:
            keypath_index = 0
            keypath_len = len(keypath)

            node = root
            sub_path = sub_identity.path
            #for _id in sub_path:
            for path_index in range(0, len(sub_path), 1):
                _id: Id = sub_path[path_index]
                if isinstance(_id, Key) and _id.is_wildcard():
                    if keypath_index < keypath_len:
                        node = node[keypath[keypath_index]]
                        keypath_index += 1
                else:
                    node = node[_id]
                if not node.exists():
                    break

            if node.exists():
                _subtrees[keypath] = node
            else:
                try_pop(_subtrees, keypath)

        self.subtrees = _subtrees

        return keypaths

    def state(self, keys: Keypath) -> ?value:
        return try_get(self.subtrees, keys)

class MirrorRefiner(Refiner):
    @property
    subtrees: dict[Keypath, TNode]
    @property
    base_path: Keypath
    @property
    num_keys: int

    def __init__(self, subscription_specs: list[SubscriptionSpec], base_path: ?Keypath):
        Refiner.__init__(self, subscription_specs, [])
        self.subtrees = {}

        if len(subscription_specs) >= 1:
            common_path = subscription_specs[0].identity.path
            for other_spec in subscription_specs[1:]:
                common_path = common_path.get_common_base_path(other_spec.identity.path)

            if base_path is not None:
                self.base_path = base_path
                if not base_path.is_sub_path(common_path):
                    raise ValueError("Subscriptions: " + list_str(subscription_specs) + " are not decendents of base_path: " + str(base_path))
            else:
                self.base_path = common_path
        else:
            self.base_path = base_path if base_path is not None else Keypath([])

        self.num_keys = _get_path_num_keys(self.base_path)

    mut def update(self, root: TNode, input_subs: dict[SubscriptionIdentity, list[Keypath]], input_refiners: dict[int, (Refiner, list[Keypath])]) -> list[Keypath]:
        keypaths: set[Keypath] = set([])
        for sub_keypaths in input_subs.values():
            for sub_keypath in sub_keypaths:
                _keypath = sub_keypath.get_slice(0, self.num_keys)
                if len(_keypath) != self.num_keys:
                    raise Exception("Broken invariant: MirrorRefiner received less than expected number of keys in updated keypath:" + str(len(_keypath)) + " != " + str(self.num_keys))
                keypaths.add(_keypath)

        for keypath in keypaths:
            keypath_index = 0
            keypath_len = len(keypath)

            node = root
            base_path = self.base_path
            for path_index in range(0, len(base_path), 1):
                _id: Id = base_path[path_index]
                if isinstance(_id, Key) and _id.is_wildcard():
                    if keypath_index < keypath_len:
                        node = node[keypath[keypath_index]]
                        keypath_index += 1
                else:
                    node = node[_id]
                if not node.exists():
                    break

            if node.exists():
                self.subtrees[keypath] = node
            else:
                try_pop(self.subtrees, keypath)

        return list(keypaths)

    def state(self, keys: Keypath) -> ?value:
        return try_get(self.subtrees, keys)

def _get_path_num_keys(path: Keypath) -> int:
    c = 0
    for _id in path:
        if isinstance(_id, Key):
            c += 1
    return c

def _get_subtree_keys(node: TNode, max_keys: int) -> list[Keypath]:
    """
        Invariant:
            Tree (node) is of a single subscription path where max_keys is the number of keys in that subscription path.
            i.e. no container siblings within the subscription path
    """

    if max_keys < 1:
        return []

    keys: list[Keypath] = []
    curr_keys: list[Id] = []
    stack: list[(TTree, int)] = []

    if isinstance(node, TTree):
        stack.append((node, 0))

        while stack:
            n, curr_keys_len = list_pop(stack)

            while len(curr_keys) > curr_keys_len:
                list_pop(curr_keys)

            key = n.key()
            if key is not None:
                curr_keys.append(key)
                if len(curr_keys) >= max_keys:
                    keys.append(Keypath(list(curr_keys)))
                    continue
                curr_keys_len += 1

            children = list(n.iter())
            if children:
                for c in list_reversed(children):
                    if isinstance(c, TTree):
                        stack.append((c, curr_keys_len))
            else:
                keys.append(Keypath(list(curr_keys)))
    return keys

class SubscriptionParams(object):
    @property
    identity: SubscriptionIdentity
    # @property
    # max_keys: int
    @property
    delete_only_filter_path: ?EKeypath

    #def __init__(self, identity: SubscriptionIdentity, max_keys: int, delete_only_filter_path: ?EKeypath):
    def __init__(self, identity: SubscriptionIdentity, delete_only_filter_path: ?EKeypath):
        self.identity = identity
        #self.max_keys = max_keys
        self.delete_only_filter_path = delete_only_filter_path

actor CdbCache(cdb_sub_conn: CdbConnection,
            cdb_cmd_conn: CdbConnection,
            shared_schema: SharedSchema,
            refiner_ctors: list[mut() -> Refiner],
            callbacks: list[(list[int], action(dict[int, list[(Keypath, ?value)]]) -> None)],
            on_error: action(Exception) -> None,
            log_handler: ?logging.Handler):

    var logh = logging.Handler("cdb-cache")
    if log_handler is not None:
        logh.set_handler(log_handler)
    var log = logging.Logger(logh)

    var _refiners: dict[int, Refiner] = {}
    var _callback_indexes: dict[int, list[int]] = {}

    #var _schema = shared_schema.shared_schema()
    var _schema = unsafe_get_shared_schema(shared_schema)

    var _sub_id_params: dict[int, SubscriptionParams] = {}
    var _pending_setup_sub_params: dict[SubscriptionIdentity, SubscriptionParams] = {}
    var __subscription_dependents: dict[SubscriptionIdentity, list[Refiner]] = {}
    var __refiner_dependents: dict[Refiner, list[Refiner]] = {}

    var _pending_sub_ids: list[int] = []
    var _pending_sub_modifications: list[(int, EList)] = []

    var _root = TTree(OP_NONE, PTag.root(), None, {})

    var _stree = STree(log)

    # Workaround actonc: Name _pending_setup_sub_params is not in scope
    def _clear_pending_setup_sub_params():
        #_pending_setup_sub_params.clear()
        _pending_setup_sub_params = {}

    def _init() -> None:
        def _assign_priority(r: Refiner):
            if r.priority == 0:
                #r.priority = 1 + max([_assign_priority(_refiners[i]) for i in r.refiner_dependencies], 0)
                mp = 0
                for i in r.refiner_dependencies:
                    dp = _assign_priority(_refiners[i])
                    if dp > mp:
                        mp = dp
                r.priority = 1 + mp
            return r.priority

        for c in refiner_ctors:
            r = c()

            for sub_spec in r.subscription_dependencies:
                _stree.add_subscription(sub_spec)
                dict_list_append(__subscription_dependents, sub_spec.identity, r)

            if r.id() in _refiners:
                raise ValueError("ERROR: CdbCache - Attempted to register duplicate refiner-id")
            _refiners[r.id()] = r

        for r in _refiners.values():
            _assign_priority(r)
            for refiner_id in r.refiner_dependencies:
                dependency = _refiners[refiner_id]
                dict_list_append(__refiner_dependents, dependency, r)

        for i in range(0, len(callbacks), 1):
            dependency_ids = callbacks[i].0
            for dependency_id in dependency_ids:
                dict_list_append(_callback_indexes, dependency_id, i)

        _pending_setup_sub_params, inner_sub_specs = _stree.prepare_subscriptions(_schema)

        _SubscriptionSetup(cdb_sub_conn, inner_sub_specs, shared_schema, _on_sub_event, _on_subscription_success, on_error, logh)

    def update() -> None:
        combined_merge_root = TTree(OP_MERGE, PTag.root(), None, {})

        # Build combined merge root
        for sub_id, etvs in _pending_sub_modifications:
            updated_keys: set[Keypath]
            try:
                merge_root = etagvals_to_merge_ttree(etvs, Cursor(_schema))
            except Exception as exc:
                log.trace("Error converting subscription event etagvals", {"etvs": etvs})
                on_error(Exception("Get modifications to tnode conversion error: " + exc.error_message))
            else:
                log.trace("Got subscription event merge root", {"sub_id": sub_id, "ttree": merge_root})
                combined_merge_root.merge(merge_root)

        _pending_sub_modifications.clear()

        log.trace("Combined merge", {"merge_root": combined_merge_root})

        # Schedule subscription-triggered refiners
        updated_subs: dict[SubscriptionIdentity, list[Keypath]] = _stree.evaluate_subscriptions(_root, combined_merge_root)
        scheduled_refiners: set[Refiner] = set([])
        #schedule_heap: MinHeap[Refiner] = MinHeap()
        schedule_heap: MinHeap_Ord2[Refiner] = MinHeap_Ord2()

        for sub_identity in updated_subs.keys():
            for refiner in __subscription_dependents[sub_identity]:
                #schedule_heap.insert(refiner)
                MinHeap_Ord2.insert(schedule_heap, refiner)
                scheduled_refiners.add(refiner)

        # Apply combined merge
        _root.merge(combined_merge_root)

        # Update refiners
        updated_refiners: dict[Refiner, list[Keypath]] = {}

        while True:
            #curr_refiner = schedule_heap.try_pop()
            curr_refiner = MinHeap_Ord2.try_pop(schedule_heap) # https://github.com/actonlang/acton/issues/1448
            if curr_refiner is not None:
                input_subs: dict[SubscriptionIdentity, list[Keypath]] = {}
                input_refiners: dict[int, (Refiner, list[Keypath])] = {}
                for sub_spec in curr_refiner.subscription_dependencies:
                    input_subs[sub_spec.identity] = updated_subs.get(sub_spec.identity, [])
                for dependency_id in curr_refiner.refiner_dependencies:
                    dependency = _refiners[dependency_id]
                    input_refiners[dependency_id] = (dependency, updated_refiners.get(dependency, []))
                updated_keys = curr_refiner.update(_root, input_subs, input_refiners)
                updated_refiners[curr_refiner] = updated_keys
                dependents = try_get(__refiner_dependents, curr_refiner)
                if dependents is not None:
                    for dependent in dependents:
                        if dependent not in scheduled_refiners:
                            #schedule_heap.insert(dependent)
                            MinHeap_Ord2.insert(schedule_heap, dependent) # https://github.com/actonlang/acton/issues/1448
                            scheduled_refiners.add(dependent)
            else:
                break

        # Invoke callbacks of updated refiners
        trigger_callback_indexes: set[int] = set([])
        for refiner in scheduled_refiners:
            refiner_id = refiner.id()
            set_update(trigger_callback_indexes, _callback_indexes.get(refiner_id, []))
        for callback_index in trigger_callback_indexes:
            dependency_ids: list[int], callback: action(dict[int, list[(Keypath, ?value)]]) -> None = callbacks[callback_index]
            args: dict[int, list[(Keypath, ?value)]] = {}
            for dependency_id in dependency_ids:
                dependency = _refiners[dependency_id]
                updates: list[(Keypath, ?value)] = []
                for keys in updated_refiners.get(dependency, []):
                    updates.append((keys, dependency.state(keys)))
                args[dependency_id] = updates

            callback(args)

    def _on_sub_event(c: CdbConnection, v: value) -> None:
        if isinstance(v, list):
            log.debug("Sub event triggered", {"sub-ids": v})
            _pending_sub_ids = v
            _do_get_modifications()
        elif isinstance(v, Exception):
            log.error("Sub event error", {"msg": v.error_message})
            on_error(Exception("Sub event error: " + v.error_message))
        else:
            log.error("Sub event error", {"msg": v})
            on_error(Exception("Sub event error: " + str(v)))

    def _do_get_modifications():
        #if _pending_sub_ids:
        if len(_pending_sub_ids) > 0:
            sub_id = list_pop(_pending_sub_ids)

            sub_params = _sub_id_params[sub_id]
            filter_path: ?EKeypath = sub_params.delete_only_filter_path

            # actonc: ?_ is not a subclass of telemetrify.nsoapi.conf.EKeypath
            #cdb_sub_conn.get_modifications(sub_id, CDB_GET_MODS_INCLUDE_LISTS | CDB_GET_MODS_WANT_ANCESTOR_DELETE, filter_path, lambda c, v: _on_get_modifications(c, v, sub_id))
            cdb_sub_conn.get_modifications(sub_id, CDB_GET_MODS_INCLUDE_LISTS | CDB_GET_MODS_WANT_ANCESTOR_DELETE, filter_path if filter_path is not None else EKeypath([]), lambda c, v: _on_get_modifications(c, v, sub_id))
        else:
            cdb_sub_conn.sync_subscription_socket(CDB_SUB_SYNC_DONE_PRIORITY, _on_sync_subscription_socket, _on_sub_event)

    def _on_get_modifications(c: CdbConnection, v: value, sub_id: int):
        if isinstance(v, EList):
            log.trace("_on_get_modification", {"eobj": v})
            _pending_sub_modifications.append((sub_id, v))
            _do_get_modifications()
        elif isinstance(v, Exception):
            log.error("Get modifications error", {"msg": v.error_message})
            on_error(Exception("Get modifications error: " + v.error_message))
        else:
            log.error("Get modifications error", {"msg": v})
            on_error(Exception("Get modifications error: " + str(v)))

    def _on_sync_subscription_socket(c: CdbConnection, v: ?Exception):
        if v is not None:
            on_error(Exception("Sub sync error: " + str(v.error_message)))
        update()

    def _on_subscription_success(sub_ids: dict[SubscriptionIdentity, int]) -> None:
        for sub_identity, sub_id in sub_ids.items():
            sub_params = _pending_setup_sub_params[sub_identity]
            _sub_id_params[sub_id] = sub_params

        #_pending_setup_sub_params.clear()
        #_pending_setup_sub_params = {}
        # Workaround actonc: Name _pending_setup_sub_params is not in scope
        _clear_pending_setup_sub_params()

        if not _trigger_subscriptions():
            _trigger_oper_subscriptions()

    def _trigger_subscriptions() -> bool:
        trigger_ids: set[int] = set([])
        for sub_id, sub_params in _sub_id_params.items():
            if sub_params.identity.sub_type != SUB_TYPE_OPERATIONAL:
                trigger_ids.add(sub_id)

        if trigger_ids:
            cdb_cmd_conn.trigger_subscriptions(list(trigger_ids), _on_trigger_subscriptions)
            return True
        return False

    def _on_trigger_subscriptions(c: CdbConnection, v: ?Exception):
        if v is not None:
            on_error(Exception("Initial trigger_subscriptions error: " + str(v.error_message)))
        else:
            _trigger_oper_subscriptions()

    def _trigger_oper_subscriptions():
        trigger_ids: list[int] = []
        for sub_id, sub_params in _sub_id_params.items():
            if sub_params.identity.sub_type == SUB_TYPE_OPERATIONAL:
                trigger_ids.append(sub_id)

        if trigger_ids:
            cdb_cmd_conn.trigger_oper_subscriptions(trigger_ids, LOCK_WAIT, _on_trigger_oper_subscriptions)

    def _on_trigger_oper_subscriptions(c: CdbConnection, v: ?Exception):
        if v is not None:
            on_error(Exception("Initial trigger_oper_subscriptions error: " + str(v.error_message)))

    _init()

class STree(object):
    @property
    root: SNode
    @property
    log: logging.Logger

    def __init__(self, log: logging.Logger):
        self.root = SNode(PTag.root(), {}, None)
        self.log = log

    def add_subscription(self, spec: SubscriptionSpec):
        return self._add_subscription(spec, None)

    def _add_subscription(self, spec: SubscriptionSpec, ancestor_delete_fallback_origin: ?SubscriptionIdentity):
        n = self.root
        for _id in spec.identity.path:
            n = n.go(_id)
        n.add_subscription(spec, ancestor_delete_fallback_origin)

    def prepare_subscriptions(self, _schema: Schema) -> (dict[SubscriptionIdentity, SubscriptionParams], list[SubscriptionSpec]):
        # Prune invalid subscriptions that are not 'required' and prepare ancestor delete fallback config subscriptions
        def _validate_and_prepare_fallback_subs(n: SNode, path: list[Id], _cursor: Cursor, is_valid: bool):
            _sdata = n.sdata
            if _sdata is not None:
                if is_valid:
                    if _sdata.identity.sub_type == SUB_TYPE_OPERATIONAL:
                        found_deletable_config_ancestor = False
                        cursor = Cursor(_schema)
                        path_len = len(path)
                        i = 0
                        while i < path_len:
                            _id = path[i]
                            if isinstance(_id, Tag):
                                cursor.push(_id)
                                schema_node = cursor.node()
                                if schema_node.is_oper():
                                    break
                                if schema_node.is_list() or schema_node.is_p_container():
                                    found_deletable_config_ancestor = True
                            i += 1
                        if found_deletable_config_ancestor:
                            self._add_subscription(
                                    SubscriptionSpec(SubscriptionIdentity(Keypath(path[0:i]), CDB_SUB_TYPE_RUNNING), _sdata.is_required),
                                    _sdata.identity)
                else:
                    if _sdata.is_required:
                        raise ValueError("Invalid subscription path: " + str(Keypath(list(path))))
                    else:
                        n.sdata = None
            return True

        self._traverse_stree(_validate_and_prepare_fallback_subs, _schema)

        # Prepare inner (i.e. actually registered to cdb) subscriptions
        params: dict[SubscriptionIdentity, SubscriptionParams] = {}
        specs: list[SubscriptionSpec] = []

        def _prepare_inner_subs(n: SNode, path: list[Id], cursor: Cursor, is_valid: bool, sub_type: int):
            _sdata = n.sdata
            if _sdata is not None:
                identity = _sdata.identity
                if identity.sub_type == sub_type:
                    do_recurse = False
                    delete_only_filter_path: ?EKeypath = None
                    ancestor_delete_fallback_origin = _sdata.ancestor_delete_fallback_origin
                    if ancestor_delete_fallback_origin is not None:
                        # TODO: Does cdb.get-modifications accept a filter path for a 'config' path that ends in 'oper'?
                        #_delete_only_filter_path: EKeypath = keypath_to_ekeypath(ancestor_delete_fallback_origin, Cursor(_schema), True)
                        # do_recurse = True
                        pass
                    params[identity] = SubscriptionParams(identity, delete_only_filter_path)
                    specs.append(SubscriptionSpec(identity, _sdata.is_required))
                    return do_recurse
            return True

        # actonc: Name n is not in scope
        #self._traverse_stree(lambda n, p, c, v: _prepare_inner_subs(n, p, c, v, SUB_TYPE_RUNNING), _schema)
        def _prepare_inner_config_subs(n: SNode, path: list[Id], cursor: Cursor, is_valid: bool):
            return _prepare_inner_subs(n, path, cursor, is_valid, SUB_TYPE_RUNNING)
        self._traverse_stree(_prepare_inner_config_subs, _schema)
        # actonc: Name n is not in scope
        #self._traverse_stree(lambda n, p, c, v: _prepare_inner_subs(n, p, c, v, SUB_TYPE_OPERATIONAL), _schema)
        def _prepare_inner_oper_subs(n: SNode, path: list[Id], cursor: Cursor, is_valid: bool):
            return _prepare_inner_subs(n, path, cursor, is_valid, SUB_TYPE_OPERATIONAL)
        self._traverse_stree(_prepare_inner_oper_subs, _schema)

        return (params, specs)

    def _traverse_stree(self, visit: mut(SNode, list[Id], Cursor, bool) -> bool, _schema: Schema):
        stack: list[(SNode, bool, bool)] = []
        for c in self.root.children.values():
            stack.append((c, True, True))

        cursor = Cursor(_schema)
        path: list[Id] = []

        while stack:
            n, is_valid, do_enter = list_pop(stack)
            n_id = n._id

            if do_enter:
                if is_valid:
                    if isinstance(n_id, Tag):
                        if not cursor.push(n_id):
                            is_valid = False
                    elif isinstance(n_id, Key):
                        if not n_id.is_wildcard():
                            # TODO: Support non-wildcard keys
                            raise ValueError("Support for non-wildcard not (yet) implemented - subscription path: " + str(Keypath(list(path))))

                path.append(n_id)

                do_recurse = visit(n, path, cursor, is_valid)

                stack.append((n, is_valid, False))

                if do_recurse:
                    for c in n.children.values():
                        stack.append((c, is_valid, True))
            else:
                list_pop(path)
                if is_valid and isinstance(n_id, Tag):
                    cursor.pop()

    def evaluate_subscriptions(self, root: TNode, merge_root: TNode) -> dict[SubscriptionIdentity, list[Keypath]]:
        trigger: dict[SubscriptionIdentity, list[Keypath]] = {}

        keys: list[Id] = []

        def _visit(state: ?TNode, update: ?TNode, parent_op: int, snode: ?SNode, s_count: int):
            is_updated: bool = False

            key: ?Key = update.key() if update is not None else state.key() if state is not None else None
            if key is not None:
                keys.append(key)

            sdata = snode.sdata if snode is not None else None
            if sdata is not None:
                s_count += 1

            op = parent_op
            if update is not None:
                op = update.op()
                if op == OP_MERGE and parent_op in [OP_REPLACE, OP_DELETE]:
                    op = OP_REPLACE

            if self.log.output_level >= logging.TRACE:
                self.log.trace("_visit(" + (optional_str(root.tag(), "None") if root is not None else "None") +
                            ", " + (optional_str(update.tag(), "None") if update is not None else "None") + ")" +
                            ", " + op_str(op) +
                            ", " + (str(sdata.identity) if sdata is not None else "None") +
                            ", " + str(s_count) +
                            ")", None)

            def _get_c_snodes(c_id: Id) -> list[SNode]:
                c_snodes: list[SNode] = []
                if snode is not None:
                    if isinstance(c_id, Key) and not c_id.is_wildcard():
                        _c_wildcard_snode = try_get(snode.children, Key.wildcard())
                        if _c_wildcard_snode is not None:
                            c_snodes.append(_c_wildcard_snode)
                    _c_snode = try_get(snode.children, c_id)
                    if _c_snode is not None:
                        c_snodes.append(_c_snode)
                return c_snodes

            if op == OP_DELETE:
                if state is not None:
                    is_updated = True

                    for c_id, c in state.iter_items():
                        if snode is not None:
                            c_snodes = _get_c_snodes(c_id)
                            for c_snode in c_snodes:
                                _visit(c, None, op, c_snode, s_count)

            elif update is not None:

                def _visit_children(update_children: Iterator[(Id, TNode)]) -> bool:
                    is_updated: bool = False
                    for c_id, c in update.iter_items():
                        c_snodes = _get_c_snodes(c_id)
                        if c_snodes:
                            for c_snode in c_snodes:
                                c_is_updated = _visit(state.get(c_id) if state is not None else None, c, op, c_snode, s_count)
                                is_updated = is_updated or c_is_updated
                        elif not is_updated and s_count > 0:
                            c_is_updated = _visit(state.get(c_id) if state is not None else None, c, op, None, s_count)
                            is_updated = is_updated or c_is_updated
                    return is_updated

                if op == OP_MERGE:
                    if state is not None:
                        is_updated = is_updated or not _eq_optional_value(update.value(), state.value())
                    else:
                        is_updated = True
                    _is_updated = _visit_children(update.iter_items())
                    is_updated = is_updated or _is_updated
                elif op == OP_REPLACE:
                    if state is not None:
                        is_updated = is_updated or not _eq_optional_value(update.value(), state.value())

                        for c_id, c in state.iter_items():
                            if not update.has_child(c_id):
                                is_updated = True
                                if snode is not None:
                                    c_snodes = _get_c_snodes(c_id)
                                    for c_snode in c_snodes:
                                        _visit(c, None, OP_DELETE, c_snode, s_count)
                        _is_updated = _visit_children(update.iter_items())
                        is_updated = is_updated or _is_updated
                    else:
                        _visit_children(update.iter_items())
                        is_updated = True
                elif op == OP_NOCREATE:
                    for c_id, c in update.iter_items():
                        c_state = state.get(c_id) if state is not None else None
                        c_snodes = _get_c_snodes(c_id)
                        if c_snodes:
                            for c_snode in c_snodes:
                                c_is_updated = _visit(c_state, c, op, c_snode, s_count)
                                is_updated = is_updated or c_is_updated
                        elif not is_updated and s_count > 0 and c_state is not None:
                            c_is_updated = _visit(c_state, c, op, None, s_count)
                            is_updated = is_updated or c_is_updated

            #if is_updated and sdata is not None and sdata.ancestor_delete_fallback_origin is None:
            if is_updated and sdata is not None:
                _sdata_ancestor_delete_fallback_origin = sdata.ancestor_delete_fallback_origin
                if _sdata_ancestor_delete_fallback_origin is None:
                    dict_list_append(trigger, sdata.identity, Keypath(keys[0:sdata.num_keys]))

            if key is not None:
                list_pop(keys)

            return is_updated

        _visit(root, merge_root, merge_root.op(), self.root, 0)

        return trigger

class SNode(object):
    @property
    _id: Id
    @property
    children: dict[Id, SNode]
    @property
    sdata: ?SData

    def __init__(self, _id: Id, children: dict[Id, SNode], sdata: ?SData):
        self._id = _id
        self.children = children
        self.sdata = sdata

    def go(self, _id: Id) -> SNode:
        return get_or_create(self.children, _id, lambda: SNode(_id, {}, None))

    def add_subscription(self, spec: SubscriptionSpec, ancestor_delete_fallback_origin: ?SubscriptionIdentity):
        _sdata = self.sdata
        if _sdata is not None:
            if spec.identity != _sdata.identity:
                raise ValueError("subscriber - Conflicting subscription specifications: " + str(spec.identity) + " vs " + str(_sdata.identity))
            #_sdata.is_required |= spec.is_required # actonc: __builtin__.bool does not implement __builtin__.Logical
            _sdata.is_required = _sdata.is_required or spec.is_required
            old_ancestor_delete_fallback_origin = _sdata.ancestor_delete_fallback_origin
            if old_ancestor_delete_fallback_origin is not None:
                pass # TODO: Find out if we even need to merge, or if we get the ancestor deletes that we want reusing the same filter-path?
            # else: # Simply drop the origin as we already have a full subscription
        else:
            self.sdata = SData(spec.identity, spec.is_required, _get_path_num_keys(spec.identity.path), ancestor_delete_fallback_origin)

class SData(object):
    @property
    identity: SubscriptionIdentity
    @property
    is_required: bool
    @property
    num_keys: int
    @property
    ancestor_delete_fallback_origin: ?SubscriptionIdentity # is not None -> Only to detect subtree deletes

    def __init__(self, identity: SubscriptionIdentity, is_required: bool, num_keys: int, ancestor_delete_fallback_origin: ?SubscriptionIdentity):
        self.identity = identity
        self.is_required = is_required
        self.ancestor_delete_fallback_origin = ancestor_delete_fallback_origin

actor _SubscriptionSetup(cdb_sub_conn: CdbConnection, subscription_specs: list[SubscriptionSpec], shared_schema: SharedSchema,
                            sub_event_cb: action(CdbConnection, value) -> None,
                            on_success: action(dict[SubscriptionIdentity, int]) -> None, on_error: action(Exception) -> None,
                            log_handler: logging.Handler):

    var log = logging.Logger(log_handler)

    #var _schema = shared_schema.shared_schema()
    var _schema = unsafe_get_shared_schema(shared_schema)

    var _subscription_points: dict[SubscriptionIdentity, int] = {}

    def _do_subscribe():
        while len(subscription_specs) != 0:
            spec = list_pop(subscription_specs)
            #ekp = keypath_to_ekeypath(path, Cursor(_schema), False)
            # Luckily IKP works for subscriptions as HKP paths with namespace transitions fail
            # during subscribe_done with error i ncserr.log where it tries to lookup a tag with the parent
            # namespace rather then the one actually specified!
            identity = spec.identity
            ekp = keypath_to_ekeypath(identity.path, Cursor(_schema), True)
            if ekp is not None:
                cdb_sub_conn.subscribe(identity.sub_type, 0, 0, ekp, lambda c, v: _on_subscribe(c, v, spec))
                return
            else:
                if spec.is_required:
                    on_error(ValueError("Invalid subscription path: " + str(spec.identity.path)))
                    return
                else:
                    log.debug("Invalid but non-required subscription", {"path": spec.identity.path})

        cdb_sub_conn.subscribe_done(_on_subscribe_done, sub_event_cb)

    def _on_subscribe(c, v, spec):
        if isinstance(v, int):
            _subscription_points[spec.identity] = v
        else:
            if spec.is_required:
                on_error(ValueError("Invalid subscription path: " + str(spec.identity.path)))
                return
            else:
                log.debug("Invalid but non-required subscription", {"path": spec.identity.path})
        _do_subscribe()

    def _on_subscribe_done(c, e):
        if e is not None:
            on_error(ValueError("Subscribe_done failed"))
        else:
            on_success(_subscription_points)

    _do_subscribe()

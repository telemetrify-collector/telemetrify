# Copyright (C) Deutsche Telekom AG
#
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

import logging
import http
import net
import time
import xml

import telemetrify.net.netconf as netconf
import telemetrify.nso.subscriber
import telemetrify.nso.writer
import telemetrify.nsoapi.cdb
import telemetrify.nsoapi.maapi
import telemetrify.nsoapi.schema as schema
import telemetrify.tsdb.writer
import tsdb.m3

from telemetrify.common.mod import *
from telemetrify.common.utils import *
from telemetrify.nso.subscriber import *
from telemetrify.nso.writer import *
from telemetrify.nsoapi.conf import *
from telemetrify.nsoapi.conv import *
from telemetrify.nsoapi.cdb import *
from telemetrify.nsoapi.maapi import *
from telemetrify.nsoapi.schema import QName, SchemaPath
from telemetrify.main.config import *
import telemetrify.vmanage.vmanage as vmanage

# class Poll(object):
#     pass

_SUBSCRIPTION_TYPE_ACTION_POLLER = PTag('tlm', 'netconf-rpc-poll')
_SUBSCRIPTION_TYPE_VMANAGE_POLLER = PTag('tlm', 'vmanage-poll')
_SUBSCRIPTION_TYPE_GET_POLLER = PTag('tlm', 'netconf-get-poll')

def tnode_empty() -> TNode:
    return TNode(OP_NONE, PTag.root())

def tnode_root() -> TNode:
    return TTree(OP_NONE, PTag.root(), None, {})

class Sink(object):
    @property
    write_fn: action(Node, TNode, TNode) -> None
    @property
    close_fn: action() -> None

    def __init__(
            self,
            write_fn: action(Node, TNode, TNode) -> None,
            close_fn: action() -> None,
            ):
        self.write_fn = write_fn
        self.close_fn = close_fn

    def write(self, node: Node, source_params: TNode, sink_config: TNode) -> None:
        self.write_fn(node, source_params, sink_config)

    def close(self):
        self.close_fn()

class Source(object):
    @property
    update_config_fn: action(?TNode, dict[Keypath, SubscriptionUpdate]) -> None
    @property
    close_fn: action() -> None
    @property
    subscription_keys: set[Keypath]

    def __init__(
            self,
            key: Keypath,
            update_config_fn: action(?TNode, dict[Keypath, SubscriptionUpdate]) -> None,
            close_fn: action() -> None
            ):
        self.key = key
        self.update_config_fn = update_config_fn
        self.close_fn = close_fn
        self.subscription_keys = set([])

    def has_subscriptions(self) -> bool:
        return bool(self.subscription_keys)

    def update_config(self, source_update: ?TNode, subscription_updates: dict[Keypath, SubscriptionUpdate]):
        for dev_sub_key, sub_update in subscription_updates.items():
            #if sub_update.config is not None:
            _config = sub_update.config
            if _config is not None:
                self.subscription_keys.add(dev_sub_key)
            else:
                self.subscription_keys.discard(dev_sub_key)

        self.update_config_fn(source_update, subscription_updates)

    def close(self):
        self.close_fn()

class Subscriber(object):
    @property
    update_config_fn: action(SubscriptionUpdate) -> None
    @property
    start_fn: action() -> None
    @property
    stop_fn: action() -> None
    @property
    close_fn: action() -> None

    def __init__(
            self,
            update_config_fn: action(SubscriptionUpdate) -> None,
            start_fn: action() -> None,
            stop_fn: action() -> None,
            close_fn: action() -> None
            ):
        self.update_config_fn = update_config_fn
        self.start_fn = start_fn
        self.stop_fn = stop_fn
        self.close_fn = close_fn

    def update_config(self, update: SubscriptionUpdate):
        self.update_config_fn(update)

    def start(self):
        self.start_fn()

    def stop(self):
        self.stop_fn()

    def close(self):
        self.close_fn()

class SubscriptionSink(object):
    @property
    config: TNode
    @property
    sink: Sink

    def __init__(self, config: TNode, sink: Sink):
        self.config = config
        self.sink = sink

    def __str__(self) -> str:
        return "SubscriptionSink(" + str(self.config) + ", " + str(self.sink) + ")"

    def write(self, node: Node, source_params: TNode) -> None:
        self.sink.write(node, source_params, self.config)

class SubscriptionSinkCollection(object):
    @property
    sub_sinks: dict[Keypath, SubscriptionSink]

    def __init__(self):
        self.sub_sinks = {}

    def update(self, sink_updates: list[(Keypath, ?SubscriptionSink)]):
        for sink_key, sink in sink_updates:
            if sink is not None:
                self.sub_sinks[sink_key] = sink
                # TODO: Signal resync where needed for differential/delta subscriptions?
            else:
                try_pop(self.sub_sinks, sink_key)

    def write(self, node: Node, source_params: TNode) -> None:
        for sub_sink in self.sub_sinks.values():
            sub_sink.write(node, source_params)

actor M3dbSink(auth: WorldCap, config: TNode, shared_schema: schema.SharedSchema):
    config_m3db = config[PTag('tlm', 'm3db')]
    address = config_m3db[PTag('tlm', 'address')].req_str()
    port = config_m3db[PTag('tlm', 'port')].req_int()

    var client: ?tsdb.m3.Client = None
    var writer: ?telemetrify.tsdb.writer.TSDBWriter = None

    print("SINK m3db CREATED")

    def write(node: Node, source_params: TNode, sink_config: TNode) -> None:
        w = writer
        if w is not None:
            _schema_path: ?value = source_params[PTag(None, 'schema_path')].value()
            schema_path: ?SchemaPath = _schema_path if _schema_path is not None and isinstance(_schema_path, SchemaPath) else None
            _timestamp: ?value = source_params[PTag(None, 'timestamp')].value()
            timestamp: time.Instant = _timestamp if _timestamp is not None and isinstance(_timestamp, time.Instant) else time.time()
            base_tags: list[(str, str)] = []
            for tag_entry in sink_config[PTag(None, 'base_tags')].iter():
                _tag = tag_entry[PTag(None, 'name')].try_str()
                _value = tag_entry[PTag(None, 'value')].try_str()
                if _tag is not None and _value is not None:
                    base_tags.append((_tag, _value))

            m3db_timestamp = timestamp.second # TODO: Subsecond precision
            # TODO:
            # Why: Cannot unify ?T_619 and telemetrify.common.mod.SchemaPath
            # when argment is ?SchemaPath ?
            #w.write(node, schema_path, [], base_tags, m3db_timestamp, _on_write_done)
            w.write(node, schema_path if schema_path is not None else SchemaPath([], []), base_tags, m3db_timestamp, _on_write_done)
        else:
            # TODO:
            # Buffer until (re-)connected or signal connection upwards for possible source subscription sync?
            # Not really relevant for periodic time-series ...
            pass
            # # <TEST>
            # _schema_path: ?value = source_params[PTag(None, 'schema_path')].value()
            # schema_path: ?SchemaPath = _schema_path if _schema_path is not None and isinstance(_schema_path, SchemaPath) else None
            # _timestamp: ?value = source_params[PTag(None, 'timestamp')].value()
            # timestamp: time.Instant = _timestamp if _timestamp is not None and isinstance(_timestamp, time.Instant) else time.time()
            # base_tags: list[(str, str)] = []
            # for tag_entry in sink_config[PTag(None, 'base_tags')].iter():
            #     _tag = tag_entry[PTag(None, 'name')].try_str()
            #     _value = tag_entry[PTag(None, 'value')].try_str()
            #     if _tag is not None and _value is not None:
            #         base_tags.append((_tag, _value))
            # m3db_timestamp = timestamp.second # TODO: Subsecond precision
            # print("SINK m3db WRITE Attempted", node, optional_str(schema_path, "None"), base_tags, m3db_timestamp)
            # # </TEST>

    def close():
        # TODO: Flush writer?
        # _writer = writer
        # if _writer is not None:
        #     _writer.flush()
        _client = client
        if _client is not None:
            # TODO:
            # _client.close()
            pass

        print("SINK m3db CLOSED")

    def _on_tsdb_connect(c: tsdb.m3.Client):
        client = c
        writer = telemetrify.tsdb.writer.TSDBWriter(c, shared_schema)
        print("SINK m3db CONNECTED")

    def _on_tsdb_error(c: tsdb.m3.Client, e):
        print("SINK m3db CLIENT ERROR:", e)
        # TODO: Reconnect ourselves or pass along upwards?

    def _on_write_done(c, e):
        if e is None:
            print("SINK m3db WRITE DONE")
        else:
            print("SINK m3db WRITE ERROR:", e)

    log_handler = logging.Handler(None)
    #log_handler.add_sink(logging.StdoutSink())

    #log = logging.Logger(log_handler)

    tsdb.m3.Client(net.TCPConnectCap(net.TCPCap(net.NetCap(auth))), address, port, _on_tsdb_connect, _on_tsdb_error, log_handler)

#actor NetconfSource(auth: WorldCap, on_ready: action(), on_error: action(str) -> None, on_closed() -> None):
actor NetconfSource(auth: WorldCap, shared_schema: schema.SharedSchema):
    var config: TNode = tnode_empty()
    var client: ?netconf.Client = None
    var client_seqno: int = 0
    var subscribers: dict[Keypath, Subscriber] = {}

    print("SOURCE netconf CREATED")

    def _on_client_connect(seqno: int):
        if seqno != client_seqno:
            return
        _start_subscribers()

    def _on_client_error(error_msg: str, seqno: int):
        if seqno != client_seqno:
            return
        _close_client()
        # TODO: Configurable retry timer/backoff?
        after 1: _connect_client()

    def _on_client_notif(node: xml.Node, seqno: int):
        # if seqno != client_seqno:
        #     return
        pass

    def update_config(source_update: ?TNode, subscription_updates: dict[Keypath, SubscriptionUpdate]):
        print("SOURCE netconf CONFIG update", optional_str(source_update, "None"))
        print("SOURCE netconf SUBSCRIPTION update", mapping_str(subscription_updates))

        restart = False

        if source_update is not None:
            if _close_client():
                restart = True

            config = source_update

            _connect_client()

        for dev_sub_key, sub_update in subscription_updates.items():
            if sub_update is not None:
                sub = try_get(subscribers, dev_sub_key)
                if sub is not None:
                    sub.update_config(sub_update)
                else:
                    new_sub = _create_subscriber(dev_sub_key, sub_update)
                    new_sub.update_config(sub_update)
                    if not restart and client is not None:
                        new_sub.start()
                    subscribers[dev_sub_key] = new_sub
            else:
                sub = try_pop(subscribers, dev_sub_key)
                if sub is not None:
                    sub.close()

        if restart:
            _start_subscribers()

    def _create_subscriber(dev_sub_key: Keypath, sub_update: SubscriptionUpdate) -> Subscriber:
        sub_config = sub_update.config
        if sub_config is not None:
            if sub_config[_SUBSCRIPTION_TYPE_ACTION_POLLER].exists():
                sub_act = NetconfRpcPollSubscription(self, dev_sub_key, shared_schema)
                return Subscriber(sub_act.update_config, sub_act.start, sub_act.stop, sub_act.close)
            elif sub_config[_SUBSCRIPTION_TYPE_GET_POLLER].exists():
                sub_act = NetconfGetPollSubscription(self, dev_sub_key, shared_schema)
                return Subscriber(sub_act.update_config, sub_act.start, sub_act.stop, sub_act.close)

        raise Exception("Broken invariant: Attempted to create subscriber from invalid config: " + optional_str(sub_config, "None"))

    def _connect_client():
        address = config[PTag('tlm', 'address')].try_str()
        port = config[PTag('tlm', 'port')].try_int()
        username = config[PTag('tlm', 'username')].try_str()
        password = config[PTag('tlm', 'password')].try_str()
        key: ?str = None # TODO

        if address is not None and port is not None and \
                username is not None and (password is not None or key is not None):

            client_seqno += 1

            def __on_client_connect(_c):
                _on_client_connect(client_seqno)
            def __on_client_error(_c, e):
                _on_client_error(e, client_seqno)
            def __on_client_notif(_c, n):
                _on_client_notif(n, client_seqno)

            new_client = netconf.Client(auth, address, port, username, password, key,
                # lambda _c: _on_client_connect(client_seqno),
                __on_client_connect,
                # lambda _c, e: _on_client_error(e, client_seqno),
                __on_client_error,
                # lambda _c, n: _on_client_notif(n, client_seqno))
                __on_client_notif)

            client = new_client

        # # <TEST>
        # after 0: _start_subscribers()
        # # </TEST>

    def _close_client() -> bool:
        _client = client
        if _client is not None:
            _stop_subscribers()
            # TODO: Gather stop replies from subscribers before closing netconf client?
            _client.close()
            client = None
            return True
        return False

    def _start_subscribers():
        for subscriber in subscribers.values():
            subscriber.start()

    def _stop_subscribers():
        for subscriber in subscribers.values():
            subscriber.stop()

    def rpc(content: xml.Node, add_rpc_attrs: list[(str, str)], callback: action(?xml.Node) -> None) -> None:
        if client is not None:
            # actonc: Acton/LambdaLifter.hs:(337,50)-(340,84): Non-exhaustive patterns in function attr
            # client.rpc(content, add_rpc_attrs, lambda _c, n: callback(n))
            def __callback(_c, n):
                callback(n)
            client.rpc(content, add_rpc_attrs, __callback)
        else:
            callback(None)

    def rpc_action(content: xml.Node, add_rpc_attrs: list[(str, str)], callback: action(?xml.Node) -> None) -> None:
        if client is not None:
            # actonc: Acton/LambdaLifter.hs:(337,50)-(340,84): Non-exhaustive patterns in function attr
            # client.rpc_action(content, add_rpc_attrs, lambda _c, n: callback(n))
            def __callback(_c, n):
                callback(n)
            client.rpc_action(content, add_rpc_attrs, __callback)
        else:
            callback(None)

    def close():
        _client = client
        if _client is not None:
            _client.close()
            client = None
        for subscriber in subscribers.values():
            subscriber.close()
        #subscribers.clear()
        subscribers = {}

#actor NetconfRpcPollSubscription(source: NetconfSource, path: str, period_ms: int):
#actor NetconfRpcPollSubscription(source: NetconfSource, config: TNode, sinks: SubscriptionSinkCollection):
actor NetconfRpcPollSubscription(source: NetconfSource, dev_sub_key: Keypath, shared_schema: schema.SharedSchema):
    _schema = schema.unsafe_get_shared_schema(shared_schema)
    sinks = SubscriptionSinkCollection()

    #var ned_id: ?HTag = HTag(710232548, 525139965) # ('http://tail-f.com/ns/ned-id/juniper-junos-nc-4.11', 'juniper-junos-nc-4.11')  # TODO: Receive NED-ID config
    var ned_id: ?HTag = HTag(817033024, 1122118695) # ('http://tail-f.com/ns/ned-id/ned-junos-23.1-yang-nc-1.0', 'ned-junos-23.1-yang-nc-1.0')  # TODO: Receive NED-ID config

    var poller_seqno: int = 0
    var rpc_xml: ?xml.Node = None
    var is_action: bool = False
    var schema_path: ?SchemaPath = None
    var period: time.Duration = time.Duration(60, 0, time.MonotonicClock(0, 0, 0))

    var is_running: bool = False

    print("SUBSCRIBER netconf-rpc-poll CREATED")

    def _do_rpc_request(seqno: int, poll_ts: time.Instant):
        if seqno != poller_seqno:
            return

        if rpc_xml is not None:
            request_ts = time.time()

            if is_action:
                source.rpc_action(rpc_xml, [], lambda r: _on_rpc_reply(seqno, poll_ts, request_ts, r))
            else:
                source.rpc(rpc_xml, [], lambda r: _on_rpc_reply(seqno, poll_ts, request_ts, r))

        #after 0.1: _on_rpc_reply(seqno, poll_ts, None)

    def _on_rpc_reply(seqno: int, last_ts: time.Instant, request_ts: time.Instant, node: ?xml.Node):
        if seqno != poller_seqno:
            return

        # # # <TEST>
        # # if node is None:
        # node = \
        #     xml.Node("rpc-reply", [(None, "urn:ietf:params:xml:ns:netconf:base:1.0")], None, [], [
        #         xml.Node("interface-information", [(None, "urn:juniper-rpc")], None, [], [
        #             xml.Node("physical-interface", [], None, [], [
        #                 xml.Node("name", [], None, [], [], "ge-0/0/0", None),
        #                 xml.Node("traffic-statistics", [], None, [], [
        #                     xml.Node("input-bytes", [], None, [], [], "12300", None),
        #                     xml.Node("output-bytes", [], None, [], [], "45600", None),
        #                     xml.Node("input-packets", [], None, [], [], "123", None),
        #                     xml.Node("output-packets", [], None, [], [], "456", None)
        #                 ], None, None)
        #             ], None, None)
        #         ], None, None)
        #     ], None, None)
        # # # </TEST>

        # TODO: Process node
        if node is not None:
            xnode = netconf.netconf_to_xnode(node, [], 0)
            print("SUBSCRIBER netconf-rpc-poll POLL:", xnode)
            source_params = tnode_root()
            source_params.leaf(None, PTag(None, 'timestamp'), request_ts)
            if schema_path is not None:
                source_params.leaf(None, PTag(None, 'schema_path'), schema_path)
            sinks.write(xnode, source_params)
        else:
            print("SUBSCRIBER netconf-rpc-poll POLL interrupted")

        #print("POLLED...")
        curr_ts = time.monotonic()
        next_ts = last_ts.add(period)
        #print("  period:", period.to_float())

        if next_ts < curr_ts:
            # Allow drift when reply arrived later than next period
            # TODO: Quantize to period?
            next_ts = curr_ts

        # print("  last_ts:", last_ts)
        # print("  curr_ts:", curr_ts)
        # print("  next_ts:", next_ts)

        delay = next_ts.since(curr_ts)
        print("  ... delay " + str(delay.to_float()) + "s")
        after delay.to_float(): _do_rpc_request(seqno, next_ts)

    #def update_sinks(sink_updates: list[(Keypath, ?SubscriptionSink)]):
    def update_config(update: SubscriptionUpdate):
        sinks.update(update.sinks)

        _config = update.config
        if _config is not None:
            _stop_poller()
            print("SUBSCRIBER netconf-rpc-poll CONFIG", _config)

            poll = _config[PTag('tlm', 'netconf-rpc-poll')]
            path = poll[PTag('tlm', 'path')].try_str()
            period_ms = poll[PTag('tlm', 'period')].try_int()

            if path is not None:
                # TODO: Proper parsing into ptag-/key-path
                #_tag = schema.QName.netconf_to_value(path, None)
                _tag = QName.netconf_to_value(path, None)
                if _tag is not None:
                    _update_rpc_params(Keypath([_tag]))

            if period_ms is not None and rpc_xml is not None:
                period = time.Duration(period_ms // 10**3, (period_ms % 10**3) * 10**15, time.MonotonicClock(0, 0, 0))
                #print("period: " + str(period.to_float()) + "s")
                if is_running:
                    _try_start_poller()
            else:
                pass # TODO: Indicate config error

    def _update_rpc_params(rpc_path: Keypath):
        _rpc_xml: ?xml.Node = None
        _is_action = False
        _schema_path: ?SchemaPath = None

        cursor = schema.Cursor(_schema)
        if cursor.push_schema_path(SchemaPath([PTag('ncs', 'devices'), PTag('ncs', 'device')], [])):
            is_cursor_ok = False
            rpc_path_len = len(rpc_path)
            if rpc_path_len == 1:
                # NED-RPC
                if cursor.push(PTag('ncs', 'rpc')):
                    if ned_id is not None and cursor.node().is_mount_point():
                        cursor.set_mount_id(ned_id)
                    unmangled_rpc_tag = rpc_path[0]
                    if isinstance(unmangled_rpc_tag, PTag):
                        prefix = unmangled_rpc_tag.prefix
                        name = unmangled_rpc_tag.name
                        if cursor.push(PTag(prefix, 'rpc-' + name)) and cursor.push(unmangled_rpc_tag):
                            is_cursor_ok = True
                        # if cursor.push(PTag(prefix, 'rpc-' + name)):
                        #     if cursor.push(unmangled_rpc_tag):
                        #         print("PING28")
                        #         is_cursor_ok = True
                        #     else:
                        #         print(optional_str(cursor.lookup_ptag(cursor.node().tag), str(cursor.node().tag)))
                        #         for c in cursor.node().children:
                        #             print("  " + optional_str(cursor.lookup_ptag(c), str(cursor.node().tag)))
                        # else:
                        #     print(optional_str(cursor.lookup_ptag(cursor.node().tag), str(cursor.node().tag)))
                        #     for c in cursor.node().children:
                        #         print("  " + optional_str(cursor.lookup_ptag(c), str(cursor.node().tag)))
            elif rpc_path_len > 1:
                # NED-ACTION
                if cursor.push(PTag('ncs', 'live-status')): # TODO: Any benefit to using PTag('ncs', 'config') instead? All actions are duplicated right?
                    if ned_id is not None and cursor.node().is_mount_point():
                        cursor.set_mount_id(ned_id)
                    is_cursor_ok = True
                    for _id in rpc_path:
                        if isinstance(_id, Tag) and not cursor.push(_id):
                            is_cursor_ok = False
                            break
                    _is_action = True

            if is_cursor_ok:
                rpc_itag = cursor.lookup_itag(cursor.node().tag)
                if rpc_itag is not None:
                    rpc_name = rpc_itag.name
                    ns = rpc_itag.ns
                    nsdefs = [(None, ns)] if ns is not None else []
                    _rpc_xml = xml.Node(rpc_itag.name, nsdefs, None, [], [], None, None)
                    _schema_path = cursor.get_schema_path()
                    # TODO: Configurable input params?

        rpc_xml = _rpc_xml
        is_action = _is_action
        schema_path = _schema_path

    def _try_start_poller():
        if rpc_xml is not None:
            curr_ts = time.monotonic()
            after 0: _do_rpc_request(poller_seqno, curr_ts)

    def _stop_poller():
        poller_seqno += 1

    def start():
        if not is_running:
            print("SUBSCRIBER netconf-rpc-poll STARTED")
            is_running = True
            _try_start_poller()

    def stop():
        if is_running:
            print("SUBSCRIBER netconf-rpc-poll STOPPED")
            is_running = False
            _stop_poller()

    def close():
        stop()

actor VManageSource(auth: WorldCap, shared_schema: schema.SharedSchema):
    var config: TNode = tnode_empty()
    var client: ?vmanage.VManageHTTPClient = None
    var client_seqno: int = 0
    var subscribers: dict[Keypath, Subscriber] = {}

    print("SOURCE vmanage CREATED")

    def _on_client_connect(seqno: int):
        if seqno != client_seqno:
            return
        _start_subscribers()

    def _on_client_error(error_msg: str, seqno: int):
        if seqno != client_seqno:
            return
        # TODO:
        # _stop_subscribers()
        pass

    def _on_client_notif(node: xml.Node, seqno: int):
        # if seqno != client_seqno:
        #     return
        pass

    def update_config(source_update: ?TNode, subscription_updates: dict[Keypath, SubscriptionUpdate]):
        print("SOURCE vmanage CONFIG update", optional_str(source_update, "None"))
        print("SOURCE vmanage SUBSCRIPTION update", mapping_str(subscription_updates))

        restart = False

        if source_update is not None:
            old_client = client
            if old_client is not None:
                _stop_subscribers()
                # TODO: Gather stop replies from subscribers before closing netconf client
                old_client.close()
                restart = True
                client = None

            config = source_update

            _connect_client()

        for dev_sub_key, sub_update in subscription_updates.items():
            if sub_update is not None:
                sub = try_get(subscribers, dev_sub_key)
                if sub is not None:
                    sub.update_config(sub_update)
                else:
                    new_sub = _create_subscriber(dev_sub_key, sub_update)
                    new_sub.update_config(sub_update)
                    if not restart and client is not None:
                        new_sub.start()
                    subscribers[dev_sub_key] = new_sub
            else:
                sub = try_pop(subscribers, dev_sub_key)
                if sub is not None:
                    sub.close()

        if restart:
            _start_subscribers()

    def _create_subscriber(dev_sub_key: Keypath, sub_update: SubscriptionUpdate) -> Subscriber:
        sub_config = sub_update.config
        if sub_config is not None:
            if sub_config[_SUBSCRIPTION_TYPE_VMANAGE_POLLER].exists():
                sub_act = VManagePollSubscription(self, dev_sub_key, shared_schema)
                return Subscriber(sub_act.update_config, sub_act.start, sub_act.stop, sub_act.close)

        raise Exception("Broken invariant: Attempted to create subscriber from invalid config: " + optional_str(sub_config, "None"))

    def _connect_client():
        address = config[PTag('tlm', 'address')].try_str()
        port = config[PTag('tlm', 'port')].try_int()
        username = config[PTag('tlm', 'username')].try_str()
        password = config[PTag('tlm', 'password')].try_str()

        if address is not None and port is not None and \
                username is not None and password is not None:

            client_seqno += 1

            def __on_client_connect(_c):
                _on_client_connect(client_seqno)
            #def __on_client_error(_c, e):
            #    _on_client_error(e, client_seqno)

            tcpccap = net.TCPConnectCap(net.TCPCap(net.NetCap(auth)))
            new_client = vmanage.VManageHTTPClient(tcpccap, address, port, username, password, __on_client_connect, None)
            client = new_client

        # # <TEST>
        # after 0: _start_subscribers()
        # # </TEST>

    def _start_subscribers():
        for subscriber in subscribers.values():
            subscriber.start()

    def _stop_subscribers():
        for subscriber in subscribers.values():
            subscriber.stop()

    def get(path: str, cb: action(?http.Response) -> None) -> None:
        if client is not None:
            def __callback(_c, n):
                cb(n)
            client.get(path, __callback)

    def close():
        _client = client
        if _client is not None:
            _client.close()
            client = None
        for subscriber in subscribers.values():
            subscriber.close()
        #subscribers.clear()
        subscribers = {}


actor VManagePollSubscription(source: VManageSource, dev_sub_key: Keypath, shared_schema: schema.SharedSchema):
    _schema = schema.unsafe_get_shared_schema(shared_schema)
    sinks = SubscriptionSinkCollection()

    var ned_id: ?HTag = HTag(710232548, 525139965) # ('http://tail-f.com/ns/ned-id/juniper-junos-nc-4.11', 'http://tail-f.com/ns/ned-id/juniper-junos-nc-4.11')  # TODO: Receive NED-ID config

    var poller_seqno: int = 0
    var poll_path: ?str = None
    var schema_path: ?SchemaPath = None
    var period: time.Duration = time.Duration(60, 0, time.MonotonicClock(0, 0, 0))

    var is_running: bool = False

    print("SUBSCRIBER vmanage CREATED")

    def _do_poll(seqno: int, poll_ts: time.Instant):
        if seqno != poller_seqno:
            return

        if poll_path is not None:
            request_ts = time.time()
            url = "/dataservice" + poll_path
            source.get("/dataservice" + poll_path, lambda r: _on_poll_reply(seqno, poll_ts, request_ts, r))
            #try:
            #    source.get("/dataservice" + poll_path, lambda r: _on_poll_reply(seqno, poll_ts, request_ts, r))
            #except vmanage.NoConnError:
            #    after 1.0: _do_poll(seqno, next_ts)


    def _on_poll_reply(seqno: int, last_ts: time.Instant, request_ts: time.Instant, reply: ?http.Response):
        if reply is not None:
            try:
                ar = reply.decode_json()
                ar_data = ar["data"]
                if isinstance(ar_data, list):
                    xnode = vmanage.approute_to_xnode(ar_data)
                    source_params = tnode_root()
                    source_params.leaf(None, PTag(None, 'timestamp'), request_ts)
                    if schema_path is not None:
                        source_params.leaf(None, PTag(None, 'schema_path'), schema_path)
                    sinks.write(xnode, source_params)
            except Exception as exc:
                print(exc)
                print(reply.body)

        curr_ts = time.monotonic()
        next_ts = last_ts.add(period)

        if next_ts < curr_ts:
            # Allow drift when reply arrived later than next period
            # TODO: Quantize to period?
            next_ts = curr_ts

        # print("  last_ts:", last_ts)
        # print("  curr_ts:", curr_ts)
        # print("  next_ts:", next_ts)

        delay = next_ts.since(curr_ts)
        after delay.to_float(): _do_poll(seqno, next_ts)

    def update_config(update: SubscriptionUpdate):
        sinks.update(update.sinks)

        _config = update.config
        if _config is not None:
            _stop_poller()

            poll = _config[PTag('tlm', 'vmanage-poll')]
            path = poll[PTag('tlm', 'path')].try_str()
            period_ms = poll[PTag('tlm', 'period')].try_int()

            if path is not None:
                poll_path = path
                # TODO: Proper parsing into ptag-/key-path
                #_tag = schema.QName.netconf_to_value(path, None)
                _tag = QName.netconf_to_value(path, None)
                if _tag is not None:
                    _update_schema_cursor(Keypath([_tag]))

            if period_ms is not None and poll_path is not None:
                period = time.Duration(period_ms // 10**3, (period_ms % 10**3) * 10**15, time.MonotonicClock(0, 0, 0))
                if is_running:
                    _try_start_poller()

    def _update_schema_cursor(kpath: Keypath):
        cursor = schema.Cursor(_schema)
        if cursor.push_schema_path(SchemaPath([PTag('ncs', 'devices'), PTag('ncs', 'device')], [])):
            if cursor.push(PTag('ncs', 'live-status')): # TODO: Any benefit to using PTag('ncs', 'config') instead? All actions are duplicated right?
                schema_path = cursor.get_schema_path()

    def _try_start_poller():
        if poll_path is not None:
            curr_ts = time.monotonic()
            after 0: _do_poll(poller_seqno, curr_ts)

    def _stop_poller():
        poller_seqno += 1

    def start():
        if not is_running:
            print("SUBSCRIBER vmanage-poll STARTED")
            is_running = True
            _try_start_poller()

    def stop():
        if is_running:
            print("SUBSCRIBER vmanage-poll STOPPED")
            is_running = False
            _stop_poller()

    def close():
        pass



actor NetconfGetPollSubscription(source: NetconfSource, dev_sub_key: Keypath, shared_schema: schema.SharedSchema, log_handler: logging.Handler):
    var logh = logging.Handler("netconf-get-poll")
    logh.set_handler(log_handler)

    var log = logging.Logger(logh)

    _schema = schema.unsafe_get_shared_schema(shared_schema)
    sinks = SubscriptionSinkCollection()

    var ned_id: ?HTag = HTag(710232548, 525139965) # ('http://tail-f.com/ns/ned-id/juniper-junos-nc-4.11', 'http://tail-f.com/ns/ned-id/juniper-junos-nc-4.11')  # TODO: Receive NED-ID config

    var poller_seqno: int = 0
    var get_xml: ?xml.Node = None
    var schema_path: ?SchemaPath = None
    var period: time.Duration = time.Duration(60, 0, time.MonotonicClock(0, 0, 0))

    var is_running: bool = False

    log.info("SUBSCRIBER netconf-get-poll CREATED", None)

    def _do_get_request(seqno: int, poll_ts: time.Instant):
        if seqno != poller_seqno:
            return

        if get_xml is not None:
            request_ts = time.time()

            source.rpc(get_xml, [], lambda r: _on_get_reply(seqno, poll_ts, request_ts, r))

        #after 0.1: _on_get_reply(seqno, poll_ts, None)

    def _on_get_reply(seqno: int, last_ts: time.Instant, request_ts: time.Instant, node: ?xml.Node):
        if seqno != poller_seqno:
            return

        # # <TEST>
        # if node is None:
        #     node = \
        #         xml.Node("interface-information", [(None, "urn:juniper-get")], None, [], [
        #             xml.Node("physical-interface", [], None, [], [
        #                 xml.Node("name", [], None, [], [], "ge-0/0/0", None),
        #                 xml.Node("traffic-statistics", [], None, [], [
        #                     xml.Node("input-bytes", [], None, [], [], "12300", None),
        #                     xml.Node("output-bytes", [], None, [], [], "45600", None),
        #                     xml.Node("input-packets", [], None, [], [], "123", None),
        #                     xml.Node("output-packets", [], None, [], [], "456", None)
        #                 ], None, None)
        #             ], None, None)
        #         ], None, None)
        # # </TEST>

        # TODO: Process node
        if node is not None:
            xnode = netconf.netconf_to_xnode(node, [], 0)
            print("SUBSCRIBER netconf-get-poll POLL:", xnode)
            source_params = tnode_root()
            source_params.leaf(None, PTag(None, 'timestamp'), request_ts)
            if schema_path is not None:
                source_params.leaf(None, PTag(None, 'schema_path'), schema_path)
            sinks.write(xnode, source_params)
        else:
            pass
            log.error("SUBSCRIBER netconf-get-poll POLL interrupted", None)

        #log.info("POLLED...", None)
        curr_ts = time.monotonic()
        next_ts = last_ts.add(period)
        #log.info("  period:", period.to_float(), None)

        if next_ts < curr_ts:
            # Allow drift when reply arrived later than next period
            # TODO: Quantize to period?
            next_ts = curr_ts

        # log.info("  last_ts:", last_ts, None)
        # log.info("  curr_ts:", curr_ts, None)
        # log.info("  next_ts:", next_ts, None)

        delay = next_ts.since(curr_ts)
        log.info("  ... delay " + str(delay.to_float()) + "s", None)
        after delay.to_float(): _do_get_request(seqno, next_ts)

    #def update_sinks(sink_updates: list[(Keypath, ?SubscriptionSink)]):
    def update_config(update: SubscriptionUpdate):
        sinks.update(update.sinks)

        _config = update.config
        if _config is not None:
            _stop_poller()
            print("SUBSCRIBER netconf-get-poll CONFIG", _config)

            poll = _config[PTag('tlm', 'netconf-get-poll')]
            path = poll[PTag('tlm', 'path')].try_str()
            period_ms = poll[PTag('tlm', 'period')].try_int()

            if path is not None:
                # TODO: Proper parsing into ptag-/key-path
                #_tag = schema.QName.netconf_to_value(path, None)
                _tag = QName.netconf_to_value(path, None)
                if _tag is not None:
                    _update_get_params(Keypath([_tag]))

            if period_ms is not None and get_xml is not None:
                period = time.Duration(period_ms // 10**3, (period_ms % 10**3) * 10**15, time.MonotonicClock(0, 0, 0))
                log.info("period: " + str(period.to_float()) + "s", None)
                if is_running:
                    _try_start_poller()
            else:
                pass # TODO: Indicate config error

    def _update_get_params(get_path: Keypath):
        _get_xml: ?xml.Node = None
        _is_action = False
        _schema_path: ?SchemaPath = None

        cursor = schema.Cursor(_schema)
        if cursor.push_schema_path(SchemaPath([PTag('ncs', 'devices'), PTag('ncs', 'device')], [])):
            is_cursor_ok = False
            _get_path: list[(str, list[(?str,str)])] = []

            # NED-GET
            if cursor.push(PTag('ncs', 'live-status')):
                if ned_id is not None and cursor.node().is_mount_point():
                    cursor.set_mount_id(ned_id)
                is_cursor_ok = True
                for _id in get_path:
                    if isinstance(_id, Tag) and not cursor.push(_id):
                        is_cursor_ok = False
                        break

                    get_itag = cursor.lookup_itag(cursor.node().tag)
                    if get_itag is not None:
                        _ns: ?str = get_itag.ns
                        if _ns is not None:
                            _nsdef: (?str,str) = (None, _ns)
                            _get_path.append((get_itag.name, [_nsdef]))
                        else:
                            _get_path.append((get_itag.name, []))

            if is_cursor_ok:
                get_itag = cursor.lookup_itag(cursor.node().tag)
                if get_itag is not None:
                    get_name = get_itag.name
                    ns = get_itag.ns
                    nsdefs = [(None, ns)] if ns is not None else []
                    _filter_node: ?xml.Node = None
                    if len(_get_path) > 0:
                        for _itag in reversed(_get_path):
                            pass
                            if _filter_node is not None:
                                _filter_node = xml.Node(_itag.0, _itag.1, None, [], [_filter_node], None, None)
                            else:
                                _filter_node = xml.Node(_itag.0, _itag.1, None, [], [], None, None)
                        _filter_node = xml.Node("filter", [], None, [("type", "subtree")], [], None, None)

                    if _filter_node is not None:
                        _get_xml = xml.Node("get", [], None, [], [_filter_node], None, None)
                    else:
                        _get_xml = xml.Node("get", [], None, [], [], None, None)
                    _schema_path = cursor.get_schema_path()
                    # TODO: Configurable input params?

        get_xml = _get_xml
        schema_path = _schema_path

    def _try_start_poller():
        if get_xml is not None:
            curr_ts = time.monotonic()
            after 0: _do_get_request(poller_seqno, curr_ts)

    def _stop_poller():
        poller_seqno += 1

    def start():
        if not is_running:
            log.info("SUBSCRIBER netconf-get-poll STARTED", None)
            is_running = True
            _try_start_poller()

    def stop():
        if is_running:
            log.info("SUBSCRIBER netconf-get-poll STOPPED", None)
            is_running = False
            _stop_poller()

    def close():
        pass

class SubscriptionUpdate(object):
    @property
    config: ?TNode
    @property
    sinks: list[(Keypath, ?SubscriptionSink)]

    def __init__(self):
        self.config = None
        self.sinks = []

    def __str__(self) -> str:
        s = []
        for sink_key, sink in self.sinks:
            unsafe_list_append(s, "(" + str(sink_key) + ", " + optional_str(sink, "None") + ")")
        return "SubscriptionUpdate(" + optional_str(self.config, "None") + ", " + str(s) + ")"

actor DeviceStreamer(auth: WorldCap, name: str, shared_schema: schema.SharedSchema):
    var sources: dict[Keypath, Source] = {}
    var subscription_sources: dict[Keypath, Keypath] = {}
    var sinks: dict[Keypath, Sink] = {}

    print("DEVICE", name, "CREATED")

    def on_config(
            updated_device_config: ?DeviceStreamerConfig,
            subscription_updates: list[(Keypath, ?value)],
            subscription_sink_updates: list[(Keypath, ?value)],
            source_updates: list[(Keypath, ?value)],
            sink_updates: list[(Keypath, ?value)]):

        print("DEVICE", name, "CONFIG", optional_str(updated_device_config, "None"))
        print("  SUBSCRIPTIONS")
        for k, v in subscription_updates:
            print("    " + str(k) + ": " + (str(v) if v is not None else "DELETED"))
        print("  SUBSCRIPTION SINKS")
        for k, v in subscription_sink_updates:
            print("    " + str(k) + ": " + (str(v) if v is not None else "DELETED"))
        print("  SOURCES")
        for k, v in source_updates:
            print("    " + str(k) + ": " + (str(v) if v is not None else "DELETED"))
        print("  SINKS")
        for k, v in sink_updates:
            print("    " + str(k) + ": " + (str(v) if v is not None else "DELETED"))

        source_config_updates: dict[Keypath, TNode] = {}
        updated_source_dev_subs: dict[Keypath, dict[Keypath, SubscriptionUpdate]] = {}

        deleted_dev_sub_keys: set[Keypath] = set([])

        # TODO:
        # Merge device_config and source_config
        # but only using source_config for a while...

        for source_key, state in source_updates:
            source_config_updates[source_key] = state if state is not None and isinstance(state, TNode) else tnode_empty()
            get_or_create(updated_source_dev_subs, source_key, lambda: {})

        if sink_updates:
            for sink_key, state in sink_updates:
                _update_sink(sink_key, state)

        for dev_sub_key, state in subscription_updates:
            if state is not None and isinstance(state, TNode):
                source_key = _get_subscription_source_key(state)
                subscription_sources[dev_sub_key] = source_key
                sub_update = get_or_create(get_or_create(updated_source_dev_subs, source_key, lambda: {}), dev_sub_key, SubscriptionUpdate)
                sub_update.config = state
            else:
                deleted_dev_sub_keys.add(dev_sub_key)

        for dev_sub_sink_key, state in subscription_sink_updates:
            dev_sub_key = dev_sub_sink_key.try_slice(0, 2)
            sink_key = dev_sub_sink_key.try_slice(2, 3)
            if dev_sub_key is not None and sink_key is not None:
                source_key = try_get(subscription_sources, dev_sub_key)
                if source_key is not None:
                    sub_update = get_or_create(get_or_create(updated_source_dev_subs, source_key, lambda: {}), dev_sub_key, SubscriptionUpdate)
                    sub_sink: ?SubscriptionSink = None
                    if state is not None and isinstance(state, TNode):
                        sink = try_get(sinks, sink_key)
                        if sink is not None:
                            sub_sink = SubscriptionSink(state, sink)
                    sub_update.sinks.append((sink_key, sub_sink))

        for dev_sub_key in deleted_dev_sub_keys:
            source_key = try_pop(subscription_sources, dev_sub_key)
            if source_key is not None:
                # sub_update = get_or_create(get_or_create(updated_source_dev_subs, source_key, lambda: {}), dev_sub_key, SubscriptionUpdate)
                # sub_update.config = None
                get_or_create(get_or_create(updated_source_dev_subs, source_key, lambda: {}), dev_sub_key, SubscriptionUpdate)

        for source_key, sub_updates in updated_source_dev_subs.items():
            source = _get_or_create_source(source_key)
            source.update_config(try_get(source_config_updates, source_key), sub_updates)
            if not source.has_subscriptions():
                source.close()
                del sources[source_key]

    def _get_subscription_source_key(state: TNode) -> Keypath:
        if state[_SUBSCRIPTION_TYPE_ACTION_POLLER].exists():
            return SOURCE_KEY_NETCONF
        if state[_SUBSCRIPTION_TYPE_VMANAGE_POLLER].exists():
            return SOURCE_KEY_VMANAGE_HTTP

        raise Exception("Unknown subscription type: " + str(state))

    def _get_or_create_source(source_key: Keypath) -> Source:
        _source = try_get(sources, source_key)
        if _source is not None:
            return _source

        if source_key == SOURCE_KEY_NETCONF:
            source_act = NetconfSource(auth, shared_schema)
            source = Source(source_key, source_act.update_config, source_act.close)
            sources[source_key] = source
            return source

        if source_key == SOURCE_KEY_VMANAGE_HTTP:
            source_act = VManageSource(auth, shared_schema)
            source = Source(source_key, source_act.update_config, source_act.close)
            sources[source_key] = source
            return source

        raise Exception("Unknown source type: " + str(source_key))

    def _update_sink(sink_key: Keypath, config: ?value):
        old_sink = try_pop(sinks, sink_key)
        if old_sink is not None:
            old_sink.close()

        if config is not None and isinstance(config, TNode):
            if config[PTag('tlm', 'm3db')].exists():
                sink_act = M3dbSink(auth, config, shared_schema)
                sink = Sink(sink_act.write, sink_act.close)
                sinks[sink_key] = sink
                return
            # if config[PTag('tlm', 'nso-data-provider')].exists():
            #     ...
            #     sinks[sink_key] = sink
            #     return

    def close() -> None:
        for source in sources.values():
            source.close()
        #sources.clear()
        sources = {}
        for sink in sinks.values():
            sink.close()
        #sinks.clear()
        sinks = {}

actor main(env):
    var device_streamers: dict[Keypath, DeviceStreamer] = {}

    def _on_maapi_connect_error(e):
        print("MAAPI connect failed:", e)

    def _on_maapi_connect(c):
        print("MAAPI connected!!!!")
        c.load_schema(_on_load_schema)

    def _on_load_schema(c, e: ?Exception, shared_schema: ?schema.SharedSchema):
        if e is None and shared_schema is not None:
            print("MAAPI loaded schema!!!!")
            cdb_connection = telemetrify.nsoapi.cdb.CdbConnection(env, 4569, "telemetrify",
                action lambda c: _on_cdb_sub_connect(c, shared_schema), _on_cdb_connect_error, None)
        else:
            print("MAAPI load schema failed:", optional_str(e, ""))
            await async env.exit(1)

    def _on_cdb_connect_error(e):
        print("CDB connect failed:", e)
        await async env.exit(1)

    def _on_cdb_sub_connect(sc, s):
        print("CDB (sub) connected!!!!")
        cdb_connection = telemetrify.nsoapi.cdb.CdbConnection(env, 4569, "telemetrify",
            action lambda cc: _on_cdb_cmd_connect(sc, cc, s), _on_cdb_connect_error, None)

    def _on_cdb_cmd_connect(sc, cc, s):
        print("CDB (cmd) connected!!!!")
        cache = telemetrify.nso.subscriber.ConfigCache(sc, cc, s,
            [
                DeviceSettingsRefiner,
                DeviceSourceNetconfRefiner,
                DeviceSourceVmanageRefiner,
                DeviceSourceRefiner,
                DeviceStreamerRefiner,
                DeviceSubscriptionSourceRefiner,
                DeviceSubscriptionSinkBaseRefiner,
                DeviceSubscriptionSinkRefiner,
                SinkRefiner,
                DeviceSinksRefiner,
            ],
            [([
                #DeviceSettingsRefiner.id(), # For DEBUG printouts only
                DeviceStreamerRefiner.id(),
                DeviceSourceNetconfRefiner.id(), # For DEBUG printouts only
                DeviceSourceVmanageRefiner.id(), # For DEBUG printouts only
                DeviceSourceRefiner.id(),
                DeviceSubscriptionSourceRefiner.id(),
                #DeviceSubscriptionSinkBaseRefiner.id(), # For DEBUG printouts purposes
                DeviceSubscriptionSinkRefiner.id(),
                #SinkRefiner.id(), # For DEBUG printouts purposes
                DeviceSinksRefiner.id()
            ],
            lambda r: _on_config_update(r, s))], _on_config_cache_error)
        #await async env.exit(0)

    def _on_config_update(refiner_updates: dict[int, list[(Keypath, ?value)]], shared_schema: schema.SharedSchema):
        for refiner_id, updates in refiner_updates.items():
            print("refiner_id: " + str(refiner_id))
            for k, v in updates:
                print("  " + str(k) + ": " + (str(v) if v is not None else "DELETED"))

        dev_config: list[(Keypath, ?value)] = refiner_updates[DeviceStreamerRefiner.id()]
        sub_config: list[(Keypath, ?value)] = refiner_updates[DeviceSubscriptionSourceRefiner.id()]
        sub_sink_config: list[(Keypath, ?value)] = refiner_updates[DeviceSubscriptionSinkRefiner.id()]
        source_config: list[(Keypath, ?value)] = refiner_updates[DeviceSourceRefiner.id()]
        # sink_config: list[(Keypath, ?value)] = refiner_updates[SinkRefiner.id()]
        sink_config: list[(Keypath, ?value)] = refiner_updates[DeviceSinksRefiner.id()]

        updated_device_keys: set[Keypath] = set([])

        updated_subscriptions: dict[Keypath, list[(Keypath, ?value)]] = {}
        updated_subscription_sinks: dict[Keypath, list[(Keypath, ?value)]] = {}
        updated_device_sources: dict[Keypath, list[(Keypath, ?value)]] = {}
        updated_device_sinks: dict[Keypath, list[(Keypath, ?value)]] = {}
        updated_device_configs: dict[Keypath, DeviceStreamerConfig] = {}

        for dev_sub_key, state in sub_config:
            device_key = dev_sub_key.try_slice(0, 1)
            if device_key is not None:
                dict_list_append(updated_subscriptions, device_key, (dev_sub_key, state))
                updated_device_keys.add(device_key)

        for dev_sub_sink_key, state in sub_sink_config:
            device_key = dev_sub_sink_key.try_slice(0, 1)
            if device_key is not None:
                dict_list_append(updated_subscription_sinks, device_key, (dev_sub_sink_key, state))
                updated_device_keys.add(device_key)

        for device_key, state in dev_config:
            if state is not None and isinstance(state, DeviceStreamerConfig):
                entry = try_get(device_streamers, device_key)
                if entry is None:
                    _device_name_key = device_key.try_get_key(0)
                    if _device_name_key is not None:
                        device_name = _device_name_key[0]
                        if isinstance(device_name, str):
                            device_streamers[device_key] = DeviceStreamer(env.cap, device_name, shared_schema)
                updated_device_keys.add(device_key)
                updated_device_configs[device_key] = state
            else:
                _remove_device_streamer(device_key)
                updated_device_keys.discard(device_key)

        for device_source_key, state in source_config:
            device_key = device_source_key.try_slice(0, 1)
            source_key = device_source_key.try_slice(1, 2)
            if device_key is not None and source_key is not None:
                dict_list_append(updated_device_sources, device_key, (source_key, state))
                updated_device_keys.add(device_key)

        for device_sink_key, state in sink_config:
            device_key = device_sink_key.try_slice(0, 1)
            sink_key = device_sink_key.try_slice(1, 2)
            if device_key is not None and sink_key is not None:
                dict_list_append(updated_device_sinks, device_key, (sink_key, state))
                updated_device_keys.add(device_key)

        for updated_device_key in updated_device_keys:
            entry = try_get(device_streamers, updated_device_key)
            if entry is not None:
                entry.on_config(
                    try_get(updated_device_configs, updated_device_key),
                    updated_subscriptions.get(updated_device_key, []),
                    updated_subscription_sinks.get(updated_device_key, []),
                    updated_device_sources.get(updated_device_key, []),
                    updated_device_sinks.get(updated_device_key, []))

    def _remove_device_streamer(device_key):
        entry = try_pop(device_streamers, device_key)
        if entry is not None:
            entry.close()

    def _on_config_cache_error(e):
        print("ConfigCache failed:", optional_str(e.error_message, ""))
        await async env.exit(1)

    print("Starting up...")
    maapi_connection = telemetrify.nsoapi.maapi.MaapiConnection(env, 4569, _on_maapi_connect, _on_maapi_connect_error, None)

# Copyright (C) Deutsche Telekom AG
#
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

import logging

import telemetrify.nso.subscriber
import telemetrify.nsoapi.cdb
import telemetrify.nsoapi.maapi
import telemetrify.nsoapi.schema as schema
import telemetrify.ietf.l3vpn_svc
import telemetrify.ietf.cat8k
import telemetrify.main.sink.m3db
import telemetrify.main.sink.nso
import telemetrify.main.source.netconf
import telemetrify.main.source.vmanage
import telemetrify.main.source.mock.netconf
import telemetrify.main.source.mock.vmanage
import telemetrify.main.subscriber.netconf
import telemetrify.main.subscriber.vmanage

from telemetrify.common.mod import *
from telemetrify.common.utils import *
from telemetrify.nso.subscriber import *
from telemetrify.nsoapi.cdb import *
from telemetrify.nsoapi.maapi import *
from telemetrify.main.common import *
from telemetrify.main.config import *
import telemetrify.vmanage.transform

class PendingSubscriberUpdate(object):
    @property
    config: ?TNode
    @property
    source_key: ?Keypath
    @property
    sink_configs: dict[Keypath, TNode]

    def __init__(self, config: ?TNode, source_key: ?Keypath, sink_configs: dict[Keypath, TNode]):
        self.config = config
        self.source_key = source_key
        self.sink_configs = sink_configs

    @staticmethod
    def make_delete():
        return PendingSubscriberUpdate(None, None, {})

    def __str__(self):
        return self.__repr__()

    def __repr__(self) -> str:
        s = []
        for sink_key, sink_config in self.sink_configs.items():
            unsafe_list_append(s, "(" + str(sink_key) + ", " + optional_str(sink_config, "None") + ")")
        return "PendingSubscriberUpdate(" + optional_str(self.config, "None") + ", " + optional_str(self.source_key, "None") + ", " + str(s) + ")"

    def is_delete(self):
        #return self.config is None and self.source_key is None and len(self.sink_configs) == 0 # actonc codegen error
        _config = self.config
        _source_key = self.source_key
        return _config is None and _source_key is None and len(self.sink_configs) == 0

    def delete(self):
        self.config = None
        self.source_key = None
        self.sink_configs = {}

    def merge(self, other: PendingSubscriberUpdate):
        if other.is_delete():
            self.delete()
            return

        _other_config = other.config
        if _other_config is not None:
            self.config = _other_config

        _other_source_key = other.source_key
        if _other_source_key is not None:
            self.source_key = _other_source_key

        for sink_key, other_sink_config in other.sink_configs.items():
            if other_sink_config:
                self.sink_configs[sink_key] = other_sink_config
            else:
                prev_sink_config = try_get(self.sink_configs, sink_key)
                if prev_sink_config is not None:
                    if bool(prev_sink_config) and not bool(other_sink_config):
                        del self.sink_configs[sink_key]
                    else:
                        self.sink_configs[sink_key] = other_sink_config
                else:
                    self.sink_configs[sink_key] = other_sink_config

class SubscriberData(object):
    @property
    subscriber: Subscriber
    @property
    pending_replacement: ?PendingSubscriberUpdate

    def __init__(self, subscriber: Subscriber):
        self.subscriber = subscriber
        self.pending_replacement = None

actor SubscriberManager(
        env: Env,
        shared_schema: schema.SharedSchema,
        shared_resources: SharedResources,
        log_handler: ?logging.Handler):

    var logh = logging.Handler("subscriber-manager")
    if log_handler is not None:
        logh.set_handler(log_handler)

    var log = logging.Logger(logh)

    var next_uid = INVALID_UID + 1

    var sources: dict[Keypath, Source] = {}
    var sinks: dict[Keypath, Sink] = {}

    var subscribers: dict[Keypath, SubscriberData] = {}
    #var pending_update_subscribers: dict[Keypath, PendingSubscriberUpdate] = {}

    def on_config_update(refiner_updates: dict[int, list[(Keypath, ?value)]], shared_schema: schema.SharedSchema):
        source_configs: list[(Keypath, ?value)] = refiner_updates[SourceRefiner.id()]
        sub_configs: list[(Keypath, ?value)] = refiner_updates[SubscriptionRefiner.id()]
        sub_type_configs: list[(Keypath, ?value)] = refiner_updates[SubscriptionTypeRefiner.id()]
        sub_source_ref_configs: list[(Keypath, ?value)] = refiner_updates[SubscriptionSourceRefRefiner.id()]
        sub_sink_configs: list[(Keypath, ?value)] = refiner_updates[SubscriptionSinkRefiner.id()]
        sink_configs: list[(Keypath, ?value)] = refiner_updates[SinkRefiner.id()]

        # Sources
        for source_key, source_config in source_configs:
            # Close old source
            old_source = try_pop(sources, source_key)
            if old_source is not None:
                old_source.close()
            # Setup new source
            if source_config is not None and isinstance(source_config, TNode):
                new_source = _create_source(source_config)
                sources[source_key] = new_source

        # Sinks
        for sink_key, sink_config in sink_configs:
            old_sink = try_pop(sinks, sink_key)
            if old_sink is not None:
                old_sink.close()
            # Setup new sink
            if sink_config is not None and isinstance(sink_config, TNode):
                new_sink = _create_sink(sink_config)
                sinks[sink_key] = new_sink

        #
        # Subscriber
        #

        pending_updates: dict[Keypath, PendingSubscriberUpdate] = {}

        def _get_or_create_pending_subscriber_update(sub_key: Keypath) -> PendingSubscriberUpdate:
            sub_update = try_get(pending_updates, sub_key)
            if sub_update is not None:
                return sub_update
            new_sub_update = PendingSubscriberUpdate(None, None, {})
            pending_updates[sub_key] = new_sub_update
            return new_sub_update

        # Subscriber sources
        for sub_source_ref_key, sub_source_ref_config in sub_source_ref_configs:
            if sub_source_ref_config is not None and isinstance(sub_source_ref_config, TNode):
                sub_update = _get_or_create_pending_subscriber_update(sub_source_ref_key)
                #source_ref = sub_source_ref_config.try_str() # actonc: #### findAttr' fails for __builtin__.value . try_str
                _sub_source_ref_config: TNode = sub_source_ref_config
                source_ref = _sub_source_ref_config.try_str()
                if source_ref is not None:
                    sub_update.source_key = Keypath([Key([source_ref])])

        # Subscriber sinks
        for sub_sink_key, sub_sink_config in sub_sink_configs:
            sub_key = sub_sink_key.try_slice(0, 1)
            sink_key = sub_sink_key.try_slice(1, 2)
            if sub_key is not None and sink_key is not None:
                sub_update = _get_or_create_pending_subscriber_update(sub_key)
                _sub_sink_config = sub_sink_config if sub_sink_config is not None and isinstance(sub_sink_config, TNode) else tnode_empty()
                sub_update.sink_configs[sink_key] = _sub_sink_config

        #sub_config_updates: dict[]
        for sub_key, sub_config in sub_configs:
            sub_update = _get_or_create_pending_subscriber_update(sub_key)
            if sub_config is not None and isinstance(sub_config, TNode):
                sub_update.config = sub_config
            else:
                sub_update.delete()

        new_sub_type_keys: set[Keypath] = set(None)
        for sub_type_key, sub_type_config in sub_type_configs:
            if sub_type_config is not None:
                new_sub_type_keys.add(sub_type_key)

        for sub_key, pending_update in pending_updates.items():
            sub = try_get(subscribers, sub_key)
            if pending_update.is_delete():
                sub_data = try_get(subscribers, sub_key)
                if sub_data is not None:
                    sub_data.subscriber.close()
                    sub_data.pending_replacement = pending_update
            else:
                if sub_key in new_sub_type_keys:
                    # New/changed subscriber-type
                    sub_data = try_get(subscribers, sub_key)
                    if sub_data is not None:
                        pending_replacement = sub_data.pending_replacement
                        if pending_replacement is not None:
                            pending_replacement.merge(pending_update)
                        else:
                            sub_data.subscriber.close()
                            sub_data.pending_replacement = pending_update
                    else:
                        new_sub = _create_subscriber(sub_key, pending_update)
                        subscribers[sub_key] = SubscriberData(new_sub)
                else:
                    # Existing, with same subscriber-type
                    sub_data = try_get(subscribers, sub_key)
                    if sub_data is not None:
                        pending_replacement = sub_data.pending_replacement
                        if pending_replacement is not None:
                            pending_replacement.merge(pending_update)
                        else:
                            sub_data.subscriber.update_config(_create_subscription_update(pending_update))

    def _create_source(config: TNode) -> Source:
        if config.has_child(SOURCE_TYPE_TAG_NETCONF):
            return telemetrify.main.source.netconf.create_netconf_source(gen_uid(), config, env.cap, shared_schema, logh)
        elif config.has_child(SOURCE_TYPE_TAG_VMANAGE_HTTP):
            return telemetrify.main.source.vmanage.create_vmanage_source(gen_uid(), config, env.cap, shared_schema, logh)
        elif config.has_child(SOURCE_TYPE_TAG_MOCK_NETCONF):
            return telemetrify.main.source.mock.netconf.create_mock_netconf_source(gen_uid(), config, logh)
        elif config.has_child(SOURCE_TYPE_TAG_MOCK_VMANAGE_HTTP):
            return telemetrify.main.source.mock.vmanage.create_mock_vmanage_source(gen_uid(), config, logh)
        raise Exception("Unknown source config: " + str(config))

    def _create_sink(config: TNode):
        if config.has_child(SINK_TYPE_TAG_M3DB):
            return telemetrify.main.sink.m3db.create_m3db_sink(gen_uid(), config, env.cap, shared_schema, logh)
        # elif config.has_child(SINK_TYPE_TAG_NSO_DP):
        #     return telemetrify.main.sink.nso.create_nso_dp_sink(gen_uid(), config, env, shared_schema, logh)
        elif config.has_child(SINK_TYPE_TAG_NSO_CDB):
            return telemetrify.main.sink.nso.create_nso_cdb_sink(gen_uid(), config, env, shared_schema, logh)
        raise Exception("Unknown sink config: " + str(config))

    def _create_subscriber(sub_key: Keypath, pending_update: PendingSubscriberUpdate) -> Subscriber:
        sub_config = pending_update.config
        if sub_config is not None:
            sub_type = get_subscription_type(sub_config)
            if sub_type is not None:
                sub = _create_subscriber_type(sub_key, sub_type)
                sub.update_config(_create_subscription_update(pending_update))
                return sub
        raise Exception("Broken invariant: Attempted to create subscriber from invalid config: " + optional_str(sub_config, "None"))

    def _create_subscriber_type(sub_key: Keypath, sub_type: Id) -> Subscriber:
        def close_cb():
            _on_subscriber_closed(sub_key)
        if sub_type == SUBSCRIPTION_TYPE_TAG_NETCONF_RPC_POLLER:
           sub_act = telemetrify.main.subscriber.netconf.NetconfRpcPollSubscription(gen_uid(), close_cb, shared_schema, logh)
           return Subscriber(sub_act.update_config, sub_act.close)
        elif sub_type == SUBSCRIPTION_TYPE_TAG_NETCONF_GET_POLLER:
            sub_act = telemetrify.main.subscriber.netconf.NetconfGetPollSubscription(gen_uid(), close_cb, shared_schema, logh)
            return Subscriber(sub_act.update_config, sub_act.close)
        elif sub_type == SUBSCRIPTION_TYPE_TAG_VMANAGE_POLLER:
            sub_act = telemetrify.main.subscriber.vmanage.VManagePollSubscription(gen_uid(), close_cb, shared_schema, logh)
            return Subscriber(sub_act.update_config, sub_act.close)
        raise Exception("Unknown subscription type: " + str(sub_type))

    def _create_subscription_update(pending_update: PendingSubscriberUpdate) -> SubscriberUpdate:
        source_key = pending_update.source_key
        source: ?Source = try_get(sources, source_key) if source_key is not None else None

        sub_sinks: list[(Keypath, ?SubscriberSink)] = []
        for sink_key, config in pending_update.sink_configs.items():
            sub_sinks.append((sink_key, _create_subscriber_sink(sink_key, config) if config is not None else None))

        return SubscriberUpdate(pending_update.config, source, sub_sinks)

    def _create_subscriber_sink(sink_key: Keypath, config: TNode) -> ?SubscriberSink:
        sink: ?Sink = try_get(sinks, sink_key)

        if sink is not None:
            head_cb: action(Node, TNode, ?action() -> None) -> None = action lambda n, p, d: sink.write(n, p, config, d)

            transforms: list[Transform] = []
            # TODO: Make sure we get elements as 'ordered-by user' from CdbCache/TNode.
            for _transform_elem in reversed(list(config[PTag('tlm', 'transform')])):
                transform = _create_transform(_transform_elem, head_cb)
                if transform is not None:
                    transforms.append(transform)
                    head_cb = transform.post # head_cb = transform.post_fn
                else:
                    pass
                    # TODO
                    # raise Exception("Unknown transform type: " + str(_transform_elem))

            return SubscriberSink(sink_key, config, sink, transforms, head_cb)

        return None

    def _create_transform(config: TNode, next_cb: action(Node, TNode, ?action() -> None) -> None) -> ?Transform:
        # Magic name string for hardcoded transform for now... i.e. demo.
        if eq_optional(config[PTag('tlm', 'name')].try_str(), "vmanage"):
            transform_act = telemetrify.vmanage.transform.Transform(
                next_cb,
                shared_resources.request_l3vpn_svc_tracker,
                shared_resources.release_l3vpn_svc_tracker,
                logh)
            return Transform(transform_act.transform, transform_act.close)
        elif eq_optional(config[PTag('tlm', 'name')].try_str(), "cat8k-ip-sla"):
            transform_act = telemetrify.ietf.cat8k.IpSlaTransform(
                next_cb,
                shared_resources.request_l3vpn_svc_tracker,
                shared_resources.release_l3vpn_svc_tracker,
                logh)
            return Transform(transform_act.transform, transform_act.close)
        return None

    def _on_subscriber_closed(sub_key: Keypath):
        sub_data = try_get(subscribers, sub_key)
        if sub_data is not None:
            pending_replacement = sub_data.pending_replacement
            if pending_replacement is not None:
                sub_data.subscriber = _create_subscriber(sub_key, pending_replacement)
                sub_data.pending_replacement = None
            else:
                del subscribers[sub_key]

    def gen_uid() -> int:
        uid = next_uid
        next_uid = uid + 1
        return uid

actor SharedResources(env: Env, shared_schema: schema.SharedSchema, log_handler: logging.Handler):
    var l3vpn_svc_tracker: ?telemetrify.ietf.l3vpn_svc.L3vpnSvcTracker = None

    # def request_l3vpn_svc_tracker(cb: action(telemetrify.ietf.l3vpn_svc.L3vpnSvcTracker) -> None):
    # TODO: Why do we get this error when there is MORE than one reference to the method, but NOT if there is ONLY one?
    # ERROR: Error when compiling telemetrify.main.main module: Type error
    #  1425:9-33
    #      |
    # 1425 |    def request_l3vpn_svc_tracker(cb: action(telemetrify.ietf.l3vpn_svc.L3vpnSvcTracker) -> None):
    #      |        ^^^^^^^^^^^^^^^^^^^^^^^^^
    # NoInfo (Loc 58253 58278) 63
    def request_l3vpn_svc_tracker(cb):
        r = l3vpn_svc_tracker
        if r is not None:
            cb(r)
        else:
            n = telemetrify.ietf.l3vpn_svc.L3vpnSvcTracker(env, shared_schema, log_handler)
            l3vpn_svc_tracker = n
            cb(n)

    def release_l3vpn_svc_tracker(tracker: telemetrify.ietf.l3vpn_svc.L3vpnSvcTracker):
        pass # TODO: Could keep refcount and release when not used

actor main(env):
    var cache: ?telemetrify.nso.subscriber.CdbCache = None
    var shared_resources: ?SharedResources = None
    var subscriber_manager: ?SubscriberManager = None

    var logh = logging.Handler("telemetrify")
    var log = logging.Logger(logh)

    logh.set_output_level(logging.NOTICE)
    logh.add_sink(logging.StdoutSink())

    def _on_maapi_connect_error(e):
        log.error("MAAPI connect failed:" + str(e), None)

    def _on_maapi_connect(c):
        log.info("MAAPI connected!!!!", None)
        c.load_schema(_on_load_schema)

    def _on_load_schema(c, e: ?Exception, shared_schema: ?schema.SharedSchema):
        if e is None and shared_schema is not None:
            log.info("MAAPI loaded schema!!!!", None)
            _shared_resources: SharedResources = SharedResources(env, shared_schema, logh)
            shared_resources = _shared_resources
            subscriber_manager = SubscriberManager(env, shared_schema, _shared_resources, logh)
            cdb_connection = telemetrify.nsoapi.cdb.CdbConnection(env, 4569, "telemetrify",
                action lambda c: _on_cdb_sub_connect(c, shared_schema), _on_cdb_connect_error, logh, None)
        else:
            log.error("MAAPI load schema failed:" + optional_str(e, ""), None)
            await async env.exit(1)

    def _on_cdb_connect_error(e):
        log.error("CDB connect failed:" + str(e), None)
        await async env.exit(1)

    def _on_cdb_sub_connect(sc, s):
        log.info("CDB (sub) connected!!!!", None)
        cdb_connection = telemetrify.nsoapi.cdb.CdbConnection(env, 4569, "telemetrify",
            action lambda cc: _on_cdb_cmd_connect(sc, cc, s), _on_cdb_connect_error, logh, None)

    def _on_cdb_cmd_connect(sc, cc, s):
        log.info("CDB (cmd) connected!!!!", None)
        cache = telemetrify.nso.subscriber.CdbCache(sc, cc, s,
            [
                SourceRefiner,
                SinkRefiner,
                SubscriptionSourceRefBaseRefiner,
                SubscriptionSourceRefRefiner,
                SubscriptionRefiner,
                SubscriptionTypeRefiner,
                SubscriptionSinkBaseRefiner,
                SubscriptionSinkRefiner,
                LoggingLevelRefiner,
            ],
            [([
                SourceRefiner.id(),
                SinkRefiner.id(),
                SubscriptionSourceRefBaseRefiner.id(),
                SubscriptionSourceRefRefiner.id(),
                SubscriptionRefiner.id(),
                SubscriptionTypeRefiner.id(),
                SubscriptionSinkBaseRefiner.id(),
                SubscriptionSinkRefiner.id(),
                LoggingLevelRefiner.id(),
            ],
            lambda r: _on_config_update(r, s))], _on_config_cache_error,
            logh)
        #await async env.exit(0)

    def _on_config_update(refiner_updates: dict[int, list[(Keypath, ?value)]], shared_schema: schema.SharedSchema):
        for refiner_id, updates in refiner_updates.items():
            log.debug("refiner_id:", {"refiner_id": refiner_id})
            _updates = {}
            for k, v in updates:
                _updates[str(k)] = str(v) if v is not None else "DELETED"
            log.debug("refiner updates", _updates)

        if subscriber_manager is not None:
            subscriber_manager.on_config_update(refiner_updates, shared_schema)

        # Logging
        _on_logging_level(refiner_updates[LoggingLevelRefiner.id()])

    # def _on_device_streamer_reached_state_trampoline(_id: DelegateId, state: int):
    #     # device_streamers.on_delegate_reached_state(_id, state)
    #     DelegateManager_on_delegate_reached_state(device_streamers, _id, state) # https://github.com/actonlang/acton/issues/1448

    def _on_logging_level(updates: list[(Keypath, ?value)]):
        level: ?int = None
        for _keypath, state in updates:
            if state is not None and isinstance(state, TNode):
                #_val = state.try_str()
                _leaf: TNode = state
                _val = _leaf.try_str()
                if _val is not None:
                    if _val == 'off':
                        level = logging.OFF
                    elif _val == 'emergency':
                        level = logging.EMERGENCY
                    elif _val == 'alert':
                        level = logging.ALERT
                    elif _val == 'critical':
                        level = logging.CRITICAL
                    elif _val == 'error':
                        level = logging.ERROR
                    elif _val == 'warning':
                        level = logging.WARNING
                    elif _val == 'info':
                        level = logging.INFO
                    elif _val == 'notice':
                        level = logging.NOTICE
                    elif _val == 'debug':
                        level = logging.DEBUG
                    elif _val == 'verbose':
                        level = logging.VERBOSE
                    elif _val == 'trace':
                        level = logging.TRACE
                    elif _val == 'all':
                        level = logging.ALL
                    else:
                        raise Exception("Unimplemented logging level value: " + str(_val))

        if level is not None:
            logh.set_output_level(level)

    def _on_config_cache_error(e):
        log.error("CdbCache failed:" + optional_str(e.error_message, ""), None)
        await async env.exit(1)

    # # Workaround compiler ordering issue
    # device_streamers._on_delegate_reached_state_trampoline_fn = _on_device_streamer_reached_state_trampoline
    # DelegateManager_set_target_state(device_streamers, STATE_RUNNING)

    log.info("Starting up...", None)
    maapi_connection = telemetrify.nsoapi.maapi.MaapiConnection(env, 4569, _on_maapi_connect, _on_maapi_connect_error, logh, None)

# Copyright (C) Deutsche Telekom AG
#
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

import logging
import time

import telemetrify.common.utils as utils

from telemetrify.common.mod import *
from telemetrify.common.utils import *
from telemetrify.nsoapi.schema import SchemaPath

def tnode_void() -> TNode:
    return TNode(OP_NONE, PTag.root())

def tnode_root() -> TNode:
    return TTree(OP_NONE, PTag.root(), None, {})

FLOW_PARAM_TIMESTAMP = PTag(None, 'timestamp')
FLOW_PARAM_SCHEMA_PATH = PTag(None, 'schema_path')
FLOW_PARAM_DELTA = PTag(None, 'delta')
FLOW_PARAM_RESET = PTag(None, 'reset')
FLOW_PARAM_RESET_BROADCAST = PTag(None, 'broadcast')
FLOW_PARAM_INTERNAL_TAGS = PTag('tlm', 'internal-tag')
FLOW_PARAM_INTERNAL_TAGS_NAME = PTag('tlm', 'name')
FLOW_PARAM_INTERNAL_TAGS_VALUE = PTag('tlm', 'value')
FLOW_PARAM_EXTERNAL_TAGS = PTag('tlm', 'external-tag')
FLOW_PARAM_EXTERNAL_TAGS_NAME = PTag('tlm', 'name')
FLOW_PARAM_EXTERNAL_TAGS_VALUE = PTag('tlm', 'value')

# STATE_NONE = 0
STATE_STOPPED = 1 # valid target-/externally-visible- state
STATE_STARTING = 2 # internal transition only, i.e. not a valid target-state
STATE_RUNNING = 3 # valid target-/externally-visible- state
STATE_RESTARTING = 5 # internal transition only, i.e. not a valid target-state
STATE_STOPPING = 6 # internal transition only, i.e. not a valid target-state
STATE_CLOSING = 8 # internal transition only, i.e. not a valid target-state
STATE_CLOSED = 9 # valid target-/externally-visible- state

def state_str(state: int) -> str:
    # if state == STATE_NONE:
    #     return "NONE"
    if state == STATE_STOPPED:
        return "STOPPED"
    elif state == STATE_STARTING:
        return "STARTING"
    elif state == STATE_RUNNING:
        return "RUNNING"
    elif state == STATE_RESTARTING:
        return "RESTARTING"
    if state == STATE_STOPPING:
        return "STOPPING"
    elif state == STATE_CLOSING:
        return "CLOSING"
    elif state == STATE_CLOSED:
        return "CLOSED"
    raise ValueError("Unknown state value: " + str(state))

OUTPUT_STATE_RESET = 0
OUTPUT_STATE_SYNCED = 2
OUTPUT_STATE_PENDING_RESET_REMOVAL = 4
OUTPUT_STATE_PENDING_RESET_RECONFIG = 6

def output_state_str(state: int) -> str:
    if state == OUTPUT_STATE_RESET:
        return "RESET"
    elif state == OUTPUT_STATE_SYNCED:
        return "SYNCED"
    elif state == OUTPUT_STATE_PENDING_RESET_REMOVAL:
        return "RESET_REMOVAL"
    elif state == OUTPUT_STATE_PENDING_RESET_RECONFIG:
        return "RESET_RECONFIG"
    raise ValueError("Unknown state value: " + str(state))

INVALID_UID = -1

def create_data_flow_params(base_flow_params: TNode, schema_path: ?SchemaPath) -> TNode:
    flow_params = base_flow_params.clone()
    flow_params.leaf(None, FLOW_PARAM_TIMESTAMP, time.time())
    if schema_path is not None:
        flow_params.leaf(None, FLOW_PARAM_SCHEMA_PATH, schema_path)
    return flow_params

def create_reset_flow_params(base_flow_params: TNode, schema_path: ?SchemaPath, broadcast: bool) -> TNode:
    flow_params = create_data_flow_params(base_flow_params, schema_path)
    reset_node = flow_params.tree(None, FLOW_PARAM_RESET)
    if broadcast:
        reset_node.leaf(None, FLOW_PARAM_RESET_BROADCAST, None)
    return flow_params

# protocol ServerProxy:
#     uid: pure() -> int
#     attach: action(int, action(int) -> None) -> None
#     detach: action(int) -> None

class Message(object):
    sender_uid: int

    def __init__(self, sender_uid: int):
        self.sender_uid = sender_uid

    def __str__(self) -> str:
        return self.__repr__()

class State(Message):
    """"State change indication"""
    state: int

    def __init__(self, sender_uid: int, state: int):
        Message.__init__(self, sender_uid)
        self.state = state

    def __repr__(self) -> str:
        return "State(%d, %s)" % (self.sender_uid, state_str(self.state))

class Resync(Message):
    """"Request a full data (i.e. replace or delete, not delta) update."""
    _workaround_actonc_issue_1598: bool

    def __init__(self, sender_uid: int):
        Message.__init__(self, sender_uid)
        self._workaround_actonc_issue_1598 = True # https://github.com/actonlang/acton/issues/1598

    def __repr__(self) -> str:
        return "Resync(%d)" % self.sender_uid

class Reset(Message):
    """"Request a delete update prior to releasing one or more downstream nodes."""
    _workaround_actonc_issue_1598: bool

    def __init__(self, sender_uid: int):
        Message.__init__(self, sender_uid)
        self._workaround_actonc_issue_1598 = True # https://github.com/actonlang/acton/issues/1598

    def __repr__(self) -> str:
        return "Reset(%d)" % self.sender_uid

class FlowNodeBase(object):
    @property
    _uid: int
    @property
    attach_fn: action(int, action(Message) -> None) -> None
    @property
    detach_fn: action(int) -> None
    @property
    close_fn: action() -> None

    def __init__(
            self,
            uid: int,
            attach_fn: action(int, action(Message) -> None) -> None,
            detach_fn: action(int) -> None,
            close_fn: action() -> None):

        self._uid = uid
        self.attach_fn = attach_fn
        self.detach_fn = detach_fn
        self.close_fn = close_fn

    def uid(self) -> int:
        return self._uid

    proc def attach(self, client_uid: int, msg_cb: action(Message) -> None):
        self.attach_fn(client_uid, msg_cb)

    proc def detach(self, client_uid: int):
        self.detach_fn(client_uid)

    proc def close(self):
        self.close_fn()

class ServerMixin(object):
    uid: int
    clients: dict[int, action(Message) -> None]

    def __init__(self, uid: int):
        self.uid = uid
        self.clients = {}

    def attach(self, client_uid: int, msg_cb: action(Message) -> None):
        self.clients[client_uid] = msg_cb
        self.on_attached(client_uid, msg_cb)

    def detach(self, client_uid: int):
        try_pop(self.clients, client_uid)

    proc def on_attached(self, client_uid: int, msg_cb: action(Message) -> None):
        pass

    def _notify_clients(self, msg: Message):
        for msg_cb in self.clients.values():
            msg_cb(msg)

    def _iter_client_uids(self) -> Iterator[int]:
        return self.clients.keys()

    def _iter_client_cbs(self) -> Iterator[(int, action(Message) -> None)]:
        return self.clients.items()

class SinkMixin(ServerMixin):
    @property # Workaround __init__ actonc: Non @property attribute on_closed cannot be mutated
    on_closed: proc() -> None

    def __init__(self, uid: int, on_closed: proc() -> None):
        ServerMixin.__init__(self, uid)
        self.on_closed = on_closed

    def on_closing(self):
        # Close immediately
        # TODO: Wait for upstream clients? Then however we might need to handle a potential consistency race if
        #       the user creates a new sink towards the same target DB.
        self.on_closed()

class SourceMixin(ServerMixin):
    @property
    state: int
    @property
    on_closed: proc() -> None

    def __init__(self, uid: int, on_closed: proc() -> None):
        ServerMixin.__init__(self, uid)
        self.state = STATE_STOPPED
        self.on_closed = on_closed

    def on_attached(self, client_uid: int, msg_cb: action(Message) -> None):
        msg_cb(State(self.uid, self.state))

    def on_started(self):
        if self.state not in [STATE_RUNNING, STATE_CLOSING]:
            self.state = STATE_RUNNING
            self._notify_clients(State(self.uid, self.state))

    def on_stopped(self):
        if self.state == STATE_RUNNING:
            self.state = STATE_STOPPED
            self._notify_clients(State(self.uid, self.state))

    def on_closing(self):
        # Close immediately
        self.on_closed()

class Output(FlowNodeBase):
    @property # Workaround __init__ actonc: Non @property attribute write_fn cannot be mutated
    write_fn: action(int, Node, TNode) -> None
    # @property
    # key: Keypath

    def __init__(
            self,
            uid: int,
            attach_fn: action(int, action(Message) -> None) -> None,
            detach_fn: action(int) -> None,
            close_fn: action() -> None,
            write_fn: action(int, Node, TNode) -> None):

        FlowNodeBase.__init__(self, uid, attach_fn, detach_fn, close_fn)
        self.write_fn = write_fn

    proc def write(self, sender_uid: int, node: Node, flow_params: TNode) -> None:
        self.write_fn(sender_uid, node, flow_params)

#
# Sink
#

class Sink(Output):
    @property
    _workaround_actonc_issue_1598: bool

    def __init__(
            self,
            uid: int,
            attach_fn: action(int, action(Message) -> None) -> None,
            detach_fn: action(int) -> None,
            close_fn: action() -> None,
            write_fn: action(int, Node, TNode) -> None):

        self._workaround_actonc_issue_1598 = True # https://github.com/actonlang/acton/issues/1598
        Output.__init__(self, uid, attach_fn, detach_fn, close_fn, write_fn)

#
# Source
#

class Source(FlowNodeBase):
    # @property
    # update_config_fn: action(TNode) -> None
    @property
    _workaround_actonc_issue_1598: bool

    def __init__(
            self,
            uid: int,
            attach_fn: action(int, action(Message) -> None) -> None,
            detach_fn: action(int) -> None,
            close_fn: action() -> None):
            #update_config_fn: action(TNode) -> None):

        self._workaround_actonc_issue_1598 = True # https://github.com/actonlang/acton/issues/1598
        FlowNodeBase.__init__(self, uid, attach_fn, detach_fn, close_fn)
        #self.update_config_fn = update_config_fn

    # def update_config(self, source_update: TNode):
    #     self.update_config_fn(source_update)

#
# Subscriber
#

class Subscriber(object):
    @property
    update_config_fn: action(SubscriberUpdate) -> None
    @property
    close_fn: action() -> None

    def __init__(
            self,
            update_config_fn: action(SubscriberUpdate) -> None,
            close_fn: action() -> None):

        self.update_config_fn = update_config_fn
        self.close_fn = close_fn

    def update_config(self, update: SubscriberUpdate):
        self.update_config_fn(update)

    def close(self):
        self.close_fn()

class SubscriberMixin(object):
    @property
    source_mixin: SubscriberSourceMixin
    @property
    output_mixin: OutputCollectionMixin
    @property
    state: int
    @property
    _start_fn: proc() -> None
    @property
    _stop_fn: proc() -> None
    @property
    _update_sub_config_fn: proc(TNode) -> None
    @property
    write_reset: proc(bool) -> None
    @property
    on_closed_fn: proc() -> None
    @property
    log: logging.Logger

    def __init__(self,
            uid: int,
            start: proc() -> None,
            stop: proc() -> None,
            update_sub_config: proc(TNode) -> None,
            source_msg_trampoline: action(Message) -> None,
            resync_source: proc() -> None,
            write_reset: proc(bool) -> None,
            output_upstream_msg_trampoline: action(Message) -> None,
            on_closed: proc() -> None,
            log: logging.Logger):

        self.source_mixin = SubscriberSourceMixin(
            uid,
            self._on_source_start,
            self._on_source_stopping,
            source_msg_trampoline)

        self.output_mixin = OutputCollectionMixin(
            uid,
            resync_source,
            self._on_request_reset,
            output_upstream_msg_trampoline,
            self._on_outputs_quiescent,
            log)

        self.state = STATE_STOPPED

        self._start_fn = start
        self._stop_fn = stop
        self._update_sub_config = update_sub_config
        self.write_reset = write_reset
        self.on_closed_fn = on_closed

        self.log = log

    def get_source(self) -> ?Source:
        return self.source_mixin.get_source()

    def write(self, sender_uid: int, node: Node, flow_params: TNode) -> None:
        self.output_mixin.write(sender_uid, node, flow_params)

    def update_config(self, update: SubscriberUpdate):
        if self._update_config_requires_restart(update):
            self._stop()
        self._update_config(update)

    def _update_config_requires_restart(self, update: SubscriberUpdate):
        _update_source = update.source
        if _update_source is not None:
            return True
        _update_config = update.config
        if _update_config is not None:
            return True

        return False

    def _update_config(self, update: SubscriberUpdate):
        self.log.trace("_update_config", {"update": update})

        if self.state in [STATE_CLOSING, STATE_CLOSED]:
            raise ValueError("Attempted config update to closing/closed subscriber")

        _config = update.config
        if _config is not None:
            self._update_sub_config_fn(_config)

        _source = update.source
        if _source is not None:
            self.source_mixin.update_source(_source)

        _outputs = update.outputs
        if _outputs:
            self.output_mixin.update(_outputs)

    def _check_state(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("_check_state", {
                "state": state_str(self.state),
                "source_state": state_str(self.source_mixin.source_state),
                "outputs_quiescent": self.output_mixin.is_quiescent()})

        if self.state == STATE_STOPPED:
            if self.source_mixin.source_state == STATE_RUNNING:
                self._start()
        elif self.state == STATE_RUNNING:
            if self.source_mixin.source_state != STATE_RUNNING:
                self._stop()
        elif self.state == STATE_CLOSING:
            if self.output_mixin.is_quiescent():
                self.state = STATE_CLOSED
                self.source_mixin.close()
                self.on_closed_fn()

    def on_started(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("on_started", None)
        if self.state in [STATE_CLOSING, STATE_CLOSED]:
            self._stop()
        else:
            self.state = STATE_RUNNING
            self.source_mixin.on_started()
            self._check_state()

    def on_stopped(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("on_stopped", None)
        if self.state not in [STATE_CLOSING, STATE_CLOSED]:
            self.state = STATE_STOPPED
            self.source_mixin.on_stopped()
        self._check_state()

    def on_source_msg(self, msg: Message):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("on_source_msg", {"msg": msg})
        self.source_mixin.on_source_msg(msg)

    def on_output_upstream_msg(self, msg: Message):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("on_output_upstream_msg", {"msg": msg})
        self.output_mixin.on_output_upstream_msg(msg)

    def _on_source_start(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("_on_source_start", None)
        self.source_mixin.on_started() # Signal early start
        self._check_state()

    def _on_source_stopping(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("_on_source_stopping", None)
        self._check_state()

    def _on_outputs_quiescent(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("_on_outputs_quiescent", None)
        self._check_state()

    def _start(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("_start", None)
        self._start_fn()

    def _stop(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("_stop", None)
        self.write_reset(True)
        self._stop_fn()

    def _on_request_reset(self) -> list[int]:
        self.write_reset(False)
        return [self.output_mixin.uid]

    # def restart(self):
    #     # Stop to be restarted if/when source & outputs are OK
    #     self._stop()

    def close(self):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("close", None)
        self.state = STATE_CLOSING
        self._stop_fn()
        self.output_mixin.close()

class SubscriberSourceMixin(object):
    @property
    uid: int
    @property
    state: int
    @property
    source_state: int
    @property
    _source: ?Source
    @property
    _has_pending_source: bool
    @property
    _pending_source: ?Source
    @property
    _source_msg_trampoline_fn: action(Message) -> None

    @property
    _start_fn: proc() -> None
    @property
    _stopping_fn: proc() -> None

    def __init__(self,
            uid: int,
            start: proc() -> None,
            stopping: proc() -> None,
            source_msg_trampoline: action(Message) -> None):

        self.uid = uid

        self.state = STATE_STOPPED
        self.source_state = STATE_STOPPED

        self._source = None
        self._has_pending_source = False
        self._pending_source = None

        self._start_fn = start
        self._stopping_fn = stopping
        self._source_msg_trampoline_fn = source_msg_trampoline

    def get_source(self) -> ?Source:
        return self._source

    def update_source(self, source: Source):
        old_source = self._source
        if old_source is not None:
            if self.state == STATE_RUNNING:
                self._has_pending_source = True
                self._pending_source = source
                self._stop()
            else:
                self._has_pending_source = False
                self._pending_source = None
                self._set_source(source)
        else:
            self._set_source(source)

    def on_started(self):
        if self.state in [STATE_STOPPING, STATE_STOPPED]:
            self._stopping_fn()

    def on_stopped(self):
        if self.state != STATE_CLOSED:
            self.state = STATE_STOPPED
            if self._has_pending_source:
                self._set_source(self._pending_source)
                self._has_pending_source = False
                self._pending_source = None

    def close(self):
        self.state = STATE_CLOSED
        self._has_pending_source = False
        self._pending_source = None
        self._set_source(None)

    def on_source_msg(self, msg: Message):
        if isinstance(msg, State):
            source = self._source
            if not (source is not None and msg.sender_uid == source.uid()):
                return

            self.source_state = msg.state

            if self.source_state == STATE_RUNNING:
                if self.state == STATE_STOPPED:
                    self._start()
            else:
                if self.state == STATE_RUNNING:
                    self._stop()

    def _set_source(self, source: ?Source):
        old_source = self._source
        if old_source is not None:
            old_source.detach(self.uid)
        self._source = source
        if source is not None:
            source.attach(self.uid, self._source_msg_trampoline_fn)

    def _stop(self):
        self.state = STATE_STOPPING
        self._stopping_fn()

    def _start(self):
        self.state = STATE_RUNNING
        self._start_fn()

class OutputData(object):
    @property
    key: Keypath
    @property
    output: Output
    @property
    state: int
    @property
    awaited_reset_client_uids: set[int]
    @property
    pending_config: TNode
    @property
    _flow_params_merge: TNode

    def __init__(self, key: Keypath, output_update: OutputUpdate):
        self.key = key
        self.output = output_update.output
        self.state = OUTPUT_STATE_RESET
        self.awaited_reset_client_uids = set(None)
        self.pending_config = output_update.config
        self._flow_params_merge = tnode_void()
        # self.process_config() # actonc: Name self is not in scope

    def __str__(self) -> str:
        return self.__repr__()

    def __repr__(self) -> str:
        return "OutputData(%s, %s, %s, %s, %s, %s)" % (
            repr(self.key), repr(self.output), output_state_str(self.state), repr(self.awaited_reset_client_uids), repr(self.pending_config), repr(self._flow_params_merge))

    @staticmethod
    def create(key: Keypath, output_update: OutputUpdate):
        output_data = OutputData(key, output_update)
        output_data.process_config()
        return output_data

    def process_config(self):
        new_merge = tnode_root()
        config = self.pending_config

        internal_tags = config[FLOW_PARAM_INTERNAL_TAGS]
        if internal_tags:
            new_merge[FLOW_PARAM_INTERNAL_TAGS] = internal_tags.clone_as(OP_MERGE)

        external_tags = config[FLOW_PARAM_EXTERNAL_TAGS]
        if external_tags:
            new_merge[FLOW_PARAM_EXTERNAL_TAGS] = external_tags.clone_as(OP_MERGE)

        self._flow_params_merge = new_merge

    def write(self, sender_uid: int, node: Node, flow_params: TNode) -> None:
        _flow_params: TNode = flow_params
        flow_params_merge = self._flow_params_merge
        if flow_params_merge:
            _flow_params = flow_params.clone().merge(flow_params_merge)
        self.output.write(sender_uid, node, _flow_params)

class OutputCollectionMixin(object):
    @property
    uid: int
    @property
    request_resync_fn: proc() -> None
    @property
    request_reset_fn: proc() -> list[int]
    @property
    output_upstream_msg_trampoline: action(Message) -> None
    @property
    on_quiescent_fn: proc() -> None
    @property
    active_outputs: dict[Keypath, OutputData]
    @property
    attached_outputs: dict[int, OutputData]
    @property
    pending_reset_uids: dict[int, set[int]] # dict[client_uid, output_uids]
    @property
    log: logging.Logger

    def __init__(self,
            uid: int,
            request_resync_fn: proc() -> None,
            request_reset_fn: proc() -> list[int],
            output_upstream_msg_trampoline: action(Message) -> None,
            on_quiescent_fn: proc() -> None,
            log: logging.Logger):

        self.uid = uid
        self.request_resync_fn = request_resync_fn
        self.request_reset_fn = request_reset_fn
        self.output_upstream_msg_trampoline = output_upstream_msg_trampoline
        self.on_quiescent_fn = on_quiescent_fn
        self.log = log

        self.active_outputs = {}
        self.attached_outputs = {}
        self.pending_reset_uids = {}

    def update(self, output_updates: list[(Keypath, ?OutputUpdate)]):
        do_resync = False
        reset_output_uids: set[int] = set(None)

        for output_key, output_update in output_updates:
            # Try remove old active output
            old_output_data = try_pop(self.active_outputs, output_key)
            if old_output_data is not None:
                if old_output_data.state == OUTPUT_STATE_RESET:
                    self._detach_output(old_output_data)
                else:
                    if old_output_data.state == OUTPUT_STATE_SYNCED:
                        reset_output_uids.add(old_output_data.output.uid())
                    old_output_data.state = OUTPUT_STATE_PENDING_RESET_REMOVAL

            # Add new output (or possibly re-add (with new config) a previously known output with pending reset)
            if output_update is not None:
                known_output_data = try_get(self.attached_outputs, output_update.output.uid())
                if known_output_data is not None:
                    # Attached but not active means it must be in OUTPUT_STATE_PENDING_RESET_REMOVAL
                    known_output_data.state = OUTPUT_STATE_PENDING_RESET_RECONFIG
                    known_output_data.pending_config = output_update.config
                    self.active_outputs[output_key] = known_output_data
                else:
                    new_output_data = OutputData.create(output_key, output_update)
                    self._attach_output(new_output_data)
                    self.active_outputs[output_key] = new_output_data

                do_resync = True

        if reset_output_uids:
            client_uids: list[int] = self.request_reset_fn()

            for output_uid in reset_output_uids:
                output_data = try_get(self.attached_outputs, output_uid)
                if output_data is not None:
                    set_update(output_data.awaited_reset_client_uids, client_uids)

            for client_uid in client_uids:
                dict_set_update(self.pending_reset_uids, client_uid, reset_output_uids)

        if do_resync:
            self.request_resync_fn()
        else:
            self._check_quiescence()

    def write(self, sender_uid: int, node: Node, flow_params: TNode) -> None:
        do_resync = False

        def _resolve_reset(output_data: OutputData):
            output_data.awaited_reset_client_uids.discard(sender_uid)
            if not output_data.awaited_reset_client_uids:
                if output_data.state == OUTPUT_STATE_PENDING_RESET_REMOVAL:
                    self._detach_output(output_data)
                elif output_data.state == OUTPUT_STATE_PENDING_RESET_RECONFIG:
                    output_data.state = OUTPUT_STATE_RESET
                    output_data.process_config()
                    do_resync = True

        reset = flow_params[FLOW_PARAM_RESET]
        is_reset = reset.exists()
        is_reset_broadcast = is_reset and reset.has_child(FLOW_PARAM_RESET_BROADCAST)
        if is_reset and not is_reset_broadcast:
            output_uids = try_pop(self.pending_reset_uids, sender_uid)
            if output_uids is not None:
                for output_uid in output_uids:
                    output_data = try_get(self.attached_outputs, output_uid)
                    if output_data is not None:
                        _resolve_reset(output_data)
                        output_data.write(self.uid, node, flow_params)
        else:
            if is_reset_broadcast:
                try_pop(self.pending_reset_uids, sender_uid)
                for output_data in self.attached_outputs.values():
                    _resolve_reset(output_data)
                    output_data.write(self.uid, node, flow_params)
            else:
                for output_data in self.active_outputs.values():
                    if output_data.state == OUTPUT_STATE_SYNCED:
                        output_data.write(self.uid, node, flow_params)
                    elif output_data.state == OUTPUT_STATE_RESET:
                        # Skip writes to new outputs until we get a non-delta payload.
                        is_delta = flow_params.has_child(FLOW_PARAM_DELTA)
                        if not is_delta:
                            output_data.state = OUTPUT_STATE_SYNCED
                            output_data.write(self.uid, node, flow_params)

        if do_resync:
            self.request_resync_fn()
        else:
            self._check_quiescence()

    def on_output_upstream_msg(self, msg: Message):
        if isinstance(msg, Resync):
            self.request_resync_fn()
        elif isinstance(msg, Reset):
            output_uid = msg.sender_uid
            output_data = try_get(self.attached_outputs, output_uid)
            if output_data is not None:
                client_uids = self.request_reset_fn()
                if client_uids:
                    set_update(output_data.awaited_reset_client_uids, client_uids)
                    for client_uid in client_uids:
                        dict_set_add(self.pending_reset_uids, client_uid, output_uid)

    def _attach_output(self, output_data: OutputData):
        self.attached_outputs[output_data.output.uid()] = output_data
        output_data.output.attach(self.uid, self.output_upstream_msg_trampoline)

    def _detach_output(self, output_data: OutputData):
        output_uid = output_data.output.uid()
        try_pop(self.attached_outputs, output_uid)
        # for client_uid in output_data.awaited_reset_client_uids:
        #     dict_set_discard(self.pending_reset_uids, client_uid, output_uid)
        output_data.output.detach(self.uid)

    def _check_quiescence(self):
        if self.is_quiescent():
            self.on_quiescent_fn()

    def is_quiescent(self) -> bool:
        return len(self.attached_outputs) == 0

    def close(self):
        output_updates: list[(Keypath, ?OutputUpdate)] = []
        for output_key in self.active_outputs.keys():
            output_updates.append((output_key, None))
        self.update(output_updates)

class OutputUpdate(object):
    @property
    config: TNode
    @property
    output: Output

    def __init__(self, config: TNode, output: Output):
        self.config = config
        self.output = output

    def __str__(self) -> str:
        return "OutputUpdate(" + str(self.config) + ", " + str(self.output) + ")"

    def __repr__(self):
        return self.__str__()

class SubscriberUpdate(object):
    @property
    config: ?TNode
    @property
    source: ?Source
    @property
    outputs: list[(Keypath, ?OutputUpdate)]

    def __init__(self, config: ?TNode, source: ?Source, outputs: list[(Keypath, ?OutputUpdate)]):
        self.config = config
        self.source = source
        self.outputs = outputs

    def __str__(self) -> str:
        s = []
        for output_key, output_update in self.outputs:
            unsafe_list_append(s, "(" + str(output_key) + ", " + optional_str(output_update, "None") + ")")
        return "SubscriberUpdate(" + optional_str(self.config, "None") + ", " + optional_str(self.source, "None") + ", " + str(s) + ")"

    def __repr__(self):
        return self.__str__()

#
# Transform
#

class Transform(Output):
    @property
    update_output_fn: action(list[(Keypath, ?OutputUpdate)]) -> None

    def __init__(
            self,
            uid: int,
            attach_fn: action(int, action(Message) -> None) -> None,
            detach_fn: action(int) -> None,
            close_fn: action() -> None,
            write_fn: action(int, Node, TNode) -> None,
            update_output_fn: action(list[(Keypath, ?OutputUpdate)]) -> None):

        Output.__init__(self, uid, attach_fn, detach_fn, close_fn, write_fn)
        self.update_output_fn = update_output_fn

    def update_output(self, update: list[(Keypath, ?OutputUpdate)]) -> None:
        self.update_output_fn(update)

class TransformMixin(ServerMixin):
    @property
    output_mixin: OutputCollectionMixin
    @property
    state: int
    @property
    on_closed: proc() -> None
    @property
    log: logging.Logger

    def __init__(self,
            uid: int,
            output_upstream_msg_trampoline: action(Message) -> None,
            on_closed: proc() -> None,
            log: logging.Logger):

        ServerMixin.__init__(self, uid)
        self.output_mixin = OutputCollectionMixin(
            uid,
            self._on_request_resync,
            self._on_request_reset,
            output_upstream_msg_trampoline,
            self._on_outputs_quiescent,
            log)
        self.state = STATE_RUNNING
        self.on_closed = on_closed
        self.log = log

    def write(self, sender_uid: int, node: Node, flow_params: TNode) -> None:
        self.output_mixin.write(sender_uid, node, flow_params)

    def update_output(self, update: list[(Keypath, ?OutputUpdate)]) -> None:
        self.output_mixin.update(update)

    def on_output_upstream_msg(self, msg: Message):
        if self.log.output_level >= logging.TRACE:
            self.log.trace("on_output_upstream_msg", {"msg": msg})
        self.output_mixin.on_output_upstream_msg(msg)

    def _on_request_resync(self):
        self._notify_clients(Resync(self.uid))

    def _on_request_reset(self):
        self._notify_clients(Reset(self.uid))
        return list(self._iter_client_uids())

    def _on_outputs_quiescent(self):
        if self.state == STATE_CLOSING:
            self.state = STATE_CLOSED
            self.on_closed()

    def close(self):
        self.output_mixin.close()

#
# Shared (transform) resources
#

class SharedResource(object):
    @property
    close_fn: ?action() -> None

    def __init__(self, close_fn: ?action() -> None):
        self.close_fn = close_fn

    def is_static(self) -> bool:
        # # return self.close_fn is None # actonc codegen error
        # _close_fn = self.close_fn
        # return _close_fn is None # actonc codegen error
        _close_fn: ?action() -> None = self.close_fn
        return False if _close_fn is not None else True


    proc def close(self):
        _close_fn = self.close_fn
        if _close_fn is not None:
            _close_fn()
